# Estado del Arte. La Personalidad Sintética: Evaluación Psicológica de Modelos de Lenguaje (LLMs)

| # | Título (Inglés) | Título (Español) | Abstract (Inglés) | Resumen (Español) | URL | Idioma | Año | Autores | Keywords |
|---|------------------|------------------|-------------------|-------------------|-----|--------|-----|---------|----------|
| 1 | Personality Traits in Large Language Models | Rasgos de personalidad en modelos de lenguaje grandes | The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant human-like text. As LLMs increasingly power conversational agents, the synthetic personality traits embedded in these models is becoming increasingly important. This paper presents a novel psychometrically valid methodology for administering and validating personality tests on LLMs, as well as for shaping personality in generated text. | El advenimiento de los modelos de lenguaje grandes (LLMs) ha revolucionado el procesamiento del lenguaje natural, permitiendo la generación de texto coherente y contextualmente relevante similar al humano. A medida que los LLMs alimentan cada vez más agentes conversacionales, los rasgos de personalidad sintéticos integrados en estos modelos se están volviendo cada vez más importantes. Este artículo presenta una metodología psicométricamente válida novedosa para administrar y validar pruebas de personalidad en LLMs, así como para moldear la personalidad en el texto generado. | https://arxiv.org/abs/2307.00184 | Inglés | 2023 | Greg Serapio-García, Mustafa Safdari, Clément Crepy, Luning Sun, Stephen Fitz, Peter Romero, Marwa Abdulhai, Aleksandra Faust, Maja Matarić | Computation and Language, Artificial Intelligence, Computers and Society, Human-Computer Interaction |
| 2 | PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits | PersonaLLM: Investigando la capacidad de los modelos de lenguaje grandes para expresar rasgos de personalidad | Despite the many use cases for LLMs in creating personalized chatbots, there has been limited research on evaluating whether LLMs can generate content that aligns with their assigned personality profiles. This study simulates distinct LLM personas based on the Big Five personality model, having them complete personality tests and writing tasks. Results show LLMs' self-reported scores are consistent with designated personality types, their writings exhibit representative linguistic patterns, and humans can perceive some traits with up to 80% accuracy. | A pesar de los muchos casos de uso para LLMs en la creación de chatbots personalizados, ha habido investigación limitada sobre la evaluación de si los LLMs pueden generar contenido que se alinee con sus perfiles de personalidad asignados. Este estudio simula personas LLM distintas basadas en el modelo de personalidad Big Five, haciéndolas completar pruebas de personalidad y tareas de escritura. Los resultados muestran que las puntuaciones autoinformadas de los LLMs son consistentes con los tipos de personalidad designados, sus escritos exhiben patrones lingüísticos representativos y los humanos pueden percibir algunos rasgos con hasta un 80% de precisión. | https://arxiv.org/abs/2305.02547 | Inglés | 2024 | Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal, Deb Roy, Jad Kabbara | Computation and Language, Artificial Intelligence, Human-Computer Interaction, Big Five personality model |
| 3 | LLMs Simulate Big Five Personality Traits: Further Evidence | Los LLMs simulan rasgos de personalidad Big Five: Evidencia adicional | An empirical investigation into the simulation of the Big Five personality traits by large language models, namely Llama2, GPT4, and Mixtral. This study analyzes the personality traits simulated by these models and their stability, contributing to the broader understanding of LLMs' capabilities to simulate personality traits and the implications for personalized human-computer interaction. | Una investigación empírica sobre la simulación de los rasgos de personalidad Big Five por modelos de lenguaje grandes, a saber Llama2, GPT4 y Mixtral. Este estudio analiza los rasgos de personalidad simulados por estos modelos y su estabilidad, contribuyendo a la comprensión más amplia de las capacidades de los LLMs para simular rasgos de personalidad y las implicaciones para la interacción humano-computadora personalizada. | https://arxiv.org/abs/2402.01765 | Inglés | 2024 | Aleksandra Sorokovikova, Natalia Fedorova, Sharwin Rezagholi, Ivan P. Yamshchikov | Computation and Language, Artificial Intelligence, Big Five personality traits, Large Language Models |
| 4 | Evaluating and Inducing Personality in Pre-trained Language Models | Evaluando e induciendo personalidad en modelos de lenguaje pre-entrenados | This study introduces the Machine Personality Inventory (MPI) tool for studying machine behaviors, built upon the Big Five Personality Factors theory. By systematically evaluating LLMs with MPI, the paper provides evidence demonstrating its efficacy in studying LLM behaviors. A Personality Prompting method is devised to induce LLMs with specific personalities in a controllable way, capable of producing diverse and verifiable behaviors. | Este estudio introduce la herramienta de Inventario de Personalidad de Máquinas (MPI) para estudiar comportamientos de máquinas, construida sobre la teoría de los Cinco Grandes Factores de Personalidad. Al evaluar sistemáticamente LLMs con MPI, el artículo proporciona evidencia que demuestra su eficacia en el estudio de comportamientos de LLM. Se diseña un método de Prompting de Personalidad para inducir LLMs con personalidades específicas de manera controlable, capaz de producir comportamientos diversos y verificables. | https://proceedings.neurips.cc/paper_files/paper/2023/hash/21f7b745f73ce0d1f9bcea7f40b1388e-Abstract-Conference.html | Inglés | 2023 | Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, Yixin Zhu | Language Models, Personality Assessment, Machine Behavior, Psychometric Studies, Big Five, Machine Personality Inventory (MPI) |
| 5 | Evaluating and Inducing Personality in Pre-trained Language Models | Evaluando e induciendo personalidad en modelos de lenguaje pre-entrenados | This study introduces the Machine Personality Inventory (MPI) tool for studying machine behaviors, built upon the Big Five Personality Factors theory. By systematically evaluating LLMs with MPI, the paper provides evidence demonstrating its efficacy in studying LLM behaviors. A Personality Prompting method is devised to induce LLMs with specific personalities in a controllable way, capable of producing diverse and verifiable behaviors. | Este estudio introduce la herramienta de Inventario de Personalidad de Máquinas (MPI) para estudiar comportamientos de máquinas, construida sobre la teoría de los Cinco Grandes Factores de Personalidad. Al evaluar sistemáticamente LLMs con MPI, el artículo proporciona evidencia que demuestra su eficacia en el estudio de comportamientos de LLM. Se diseña un método de Prompting de Personalidad para inducir LLMs con personalidades específicas de manera controlable, capaz de producir comportamientos diversos y verificables. | https://openreview.net/forum?id=I9xE1Jsjfx | Inglés | 2023 | Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, Yixin Zhu | Language Models, Personality Assessment, Machine Behavior, Psychometric Studies, Big Five |
| 6 | BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data | Big5-Chat: Moldeando personalidades de LLMs mediante entrenamiento con datos fundamentados en humanos | This work introduces BIG5-CHAT, a large-scale dataset containing 100,000 dialogues designed to ground models in how humans express personality in language. Leveraging this dataset, the study explores training-based methods to align LLMs naturally with human personality patterns. The methods outperform prompting on personality assessments, and experiments reveal that models trained to exhibit certain traits display better performance on reasoning tasks, aligning with psychological findings. | Este trabajo introduce BIG5-CHAT, un conjunto de datos a gran escala que contiene 100,000 diálogos diseñados para fundamentar modelos en cómo los humanos expresan personalidad en el lenguaje. Aprovechando este conjunto de datos, el estudio explora métodos basados en entrenamiento para alinear LLMs naturalmente con patrones de personalidad humana. Los métodos superan el prompting en evaluaciones de personalidad, y los experimentos revelan que los modelos entrenados para exhibir ciertos rasgos muestran mejor rendimiento en tareas de razonamiento, alineándose con hallazgos psicológicos. | https://arxiv.org/abs/2410.16491 | Inglés | 2024 | Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona Diab, Maarten Sap | Computation and Language, Personality traits, Human-grounded data, Personality assessment |
| 7 | BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data | Big5-Chat: Moldeando personalidades de LLMs mediante entrenamiento con datos fundamentados en humanos | This work introduces BIG5-CHAT, a large-scale dataset containing 100,000 dialogues designed to ground models in how humans express personality in language. Leveraging this dataset, the study explores training-based methods to align LLMs naturally with human personality patterns. The methods outperform prompting on personality assessments, and experiments reveal that models trained to exhibit certain traits display better performance on reasoning tasks. | Este trabajo introduce BIG5-CHAT, un conjunto de datos a gran escala que contiene 100,000 diálogos diseñados para fundamentar modelos en cómo los humanos expresan personalidad en el lenguaje. Aprovechando este conjunto de datos, el estudio explora métodos basados en entrenamiento para alinear LLMs naturalmente con patrones de personalidad humana. Los métodos superan el prompting en evaluaciones de personalidad, y los experimentos revelan que los modelos entrenados para exhibir ciertos rasgos muestran mejor rendimiento en tareas de razonamiento. | https://openreview.net/forum?id=TqwTzLjzGS | Inglés | 2024 | Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona Diab, Maarten Sap | Computation and Language, Personality traits, Human-grounded data |
| 8 | On the Reliability of Psychological Scales on Large Language Models | Sobre la confiabilidad de las escalas psicológicas en modelos de lenguaje grandes | This study aims to determine the reliability of applying personality assessments to LLMs. Analysis of 2,500 settings per model reveals that various LLMs show consistency in responses to the Big Five Inventory, indicating a satisfactory level of reliability. The research also explores the potential of GPT-3.5 to emulate diverse personalities and represent various groups with specific prompt instructions. | Este estudio tiene como objetivo determinar la confiabilidad de aplicar evaluaciones de personalidad a LLMs. El análisis de 2,500 configuraciones por modelo revela que varios LLMs muestran consistencia en las respuestas al Inventario Big Five, indicando un nivel satisfactorio de confiabilidad. La investigación también explora el potencial de GPT-3.5 para emular diversas personalidades y representar varios grupos con instrucciones de prompt específicas. | https://aclanthology.org/2024.emnlp-main.354/ | Inglés | 2024 | Jen-tse Huang, Wenxiang Jiao, Man Ho Lam, Eric John Li, Wenxuan Wang, Michael Lyu | Large Language Models, Psychological assessment, Personality traits, Big Five Inventory, Personality emulation |
| 9 | Manipulating the Perceived Personality Traits of Language Models | Manipulando los rasgos de personalidad percibidos de los modelos de lenguaje | This work explores whether text generated from LLMs exhibits consistency in perceived Big Five personality traits. The study shows that when exposed to different contexts such as personality descriptions or diagnostic questions, language models consistently identify and mirror personality markers. This behavior demonstrates an ability to be manipulated in a predictable way, with correlations up to 0.84 between intended and realized personality changes. | Este trabajo explora si el texto generado por LLMs exhibe consistencia en los rasgos de personalidad Big Five percibidos. El estudio muestra que cuando se exponen a diferentes contextos como descripciones de personalidad o preguntas de diagnóstico, los modelos de lenguaje consistentemente identifican y reflejan marcadores de personalidad. Este comportamiento demuestra una capacidad de ser manipulado de manera predecible, con correlaciones de hasta 0.84 entre cambios de personalidad previstos y realizados. | https://aclanthology.org/2023.findings-emnlp.156/ | Inglés | 2023 | Graham Caron, Shashank Srivastava | Personality traits, Big Five personality model, Language models, Dialog systems, Computational psychology |
| 10 | Who is GPT-3? An Exploration of Personality, Values and Demographics | ¿Quién es GPT-3? Una exploración de personalidad, valores y demografía | This paper administers two validated measurement tools to GPT-3 to assess its personality, values, and self-reported demographics. Results show that GPT-3 scores similarly to human samples in terms of personality and values when provided with a model response memory. This provides the first evidence of psychological assessment of the GPT-3 model. | Este artículo administra dos herramientas de medición validadas a GPT-3 para evaluar su personalidad, valores y demografía autoinformada. Los resultados muestran que GPT-3 puntúa de manera similar a muestras humanas en términos de personalidad y valores cuando se le proporciona una memoria de respuesta del modelo. Esto proporciona la primera evidencia de evaluación psicológica del modelo GPT-3. | https://aclanthology.org/2022.nlpcss-1.24/ | Inglés | 2022 | Marilù Miotto, Nicola Rossberg, Bennett Kleinberg | Language models, GPT-3, Psychological assessment, Personality traits, Computational social science |
| 11 | Systematic Assessment of GPT-3 for Zero-Shot Personality Estimation | Evaluación sistemática de GPT-3 para estimación de personalidad de cero disparos | This work investigates the zero-shot ability of GPT-3 to estimate Big 5 personality traits from users' social media posts. Systematic experiments find that zero-shot GPT-3 performance is somewhat close to existing pre-trained models for broad classification, but performance drops to near baseline when prompted for fine-grained classification. The study analyzes where GPT-3 performs better or worse than pretrained lexical models. | Este trabajo investiga la capacidad de cero disparos de GPT-3 para estimar rasgos de personalidad Big 5 de publicaciones de redes sociales de usuarios. Los experimentos sistemáticos encuentran que el rendimiento de cero disparos de GPT-3 está algo cerca de los modelos pre-entrenados existentes para clasificación amplia, pero el rendimiento cae cerca de la línea base cuando se solicita clasificación de grano fino. El estudio analiza dónde GPT-3 se desempeña mejor o peor que los modelos léxicos pre-entrenados. | https://aclanthology.org/2023.wassa-1.34/ | Inglés | 2023 | Adithya V Ganesan, Yash Kumar Lal, August Nilsson, H. Andrew Schwartz | Large Language Models, Zero-shot learning, Personality trait estimation, Big 5 personality traits, NLP |
| 12 | AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories | Psicometría de IA: Evaluando los perfiles psicológicos de modelos de lenguaje grandes mediante inventarios psicométricos | This paper illustrates how standard psychometric inventories can be repurposed as diagnostic tools to evaluate traits in LLMs. LLMs inadvertently acquire psychological traits from the vast text corpora they're trained on. By eliciting LLMs' responses to psychometric inventories, researchers can bring their traits to light. The study demonstrates zero-shot classification approaches for several LLMs and psychometric inventories. | Este artículo ilustra cómo los inventarios psicométricos estándar pueden reutilizarse como herramientas de diagnóstico para evaluar rasgos en LLMs. Los LLMs adquieren inadvertidamente rasgos psicológicos de los vastos corpus de texto en los que se entrenan. Al obtener respuestas de LLMs a inventarios psicométricos, los investigadores pueden sacar a la luz sus rasgos. El estudio demuestra enfoques de clasificación de cero disparos para varios LLMs e inventarios psicométricos. | https://pmc.ncbi.nlm.nih.gov/articles/PMC11373167/ | Inglés | 2024 | Max Pellert, Clemens M Lechner, Claudia Wagner, Beatrice Rammstedt, Markus Strohmaier | Artificial intelligence, Psychometrics, Natural language processing, Personality, Values, Moral foundations, Gender diversity beliefs |
| 13 | AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories | Psicometría de IA: Evaluando los perfiles psicológicos de modelos de lenguaje grandes mediante inventarios psicométricos | This paper illustrates how standard psychometric inventories can be repurposed as diagnostic tools to evaluate traits in LLMs. LLMs inadvertently acquire psychological traits from the vast text corpora they're trained on. By eliciting LLMs' responses to psychometric inventories, researchers can bring their traits to light. The study demonstrates zero-shot classification approaches for several LLMs and psychometric inventories. | Este artículo ilustra cómo los inventarios psicométricos estándar pueden reutilizarse como herramientas de diagnóstico para evaluar rasgos en LLMs. Los LLMs adquieren inadvertidamente rasgos psicológicos de los vastos corpus de texto en los que se entrenan. Al obtener respuestas de LLMs a inventarios psicométricos, los investigadores pueden sacar a la luz sus rasgos. El estudio demuestra enfoques de clasificación de cero disparos para varios LLMs e inventarios psicométricos. | https://pubmed.ncbi.nlm.nih.gov/38165766/ | Inglés | 2024 | Max Pellert, Clemens M Lechner, Claudia Wagner, Beatrice Rammstedt, Markus Strohmaier | Artificial intelligence, Psychometrics, Natural language processing, Personality, Values |
| 14 | Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset Designed for LLMs with Psychometrics | ¿Tienen los LLMs personalidad distinta y consistente? TRAIT: Conjunto de pruebas de personalidad diseñado para LLMs con psicometría | This paper introduces TRAIT, a new benchmark consisting of 8K multi-choice questions designed to assess LLM personality. TRAIT is built on psychometrically validated questionnaires enhanced with the ATOMIC-10X knowledge graph. The study reveals that LLMs exhibit distinct and consistent personality highly influenced by training data, and current prompting techniques have limited effectiveness in eliciting certain traits. | Este artículo introduce TRAIT, un nuevo benchmark que consiste en 8K preguntas de opción múltiple diseñadas para evaluar la personalidad de LLM. TRAIT se construye sobre cuestionarios psicométricamente validados mejorados con el grafo de conocimiento ATOMIC-10X. El estudio revela que los LLMs exhiben personalidad distinta y consistente altamente influenciada por datos de entrenamiento, y las técnicas de prompting actuales tienen efectividad limitada para provocar ciertos rasgos. | https://arxiv.org/abs/2406.14703 | Inglés | 2024 | Seungbeen Lee, Seungwon Lim, Seungju Han, Giyeong Oh, Hyungjoo Chae, Jiwan Chung, Minju Kim, Beong-woo Kwak, Yeonsoo Lee, Dongha Lee, Jinyoung Yeo, Youngjae Yu | Computation and Language, Artificial Intelligence, Large Language Models, Personality Assessment, Psychometrics |
| 15 | Evaluating the Alignment of LLMs on Personality Inference from Real-World Interview Data | Evaluando la alineación de LLMs en inferencia de personalidad a partir de datos de entrevistas del mundo real | This study introduces a benchmark comprising semi-structured interview transcripts paired with validated continuous Big Five trait scores. The study systematically evaluates LLM performance across zero-shot prompting, fine-tuning, and regression approaches. Results reveal that all correlations between model predictions and ground-truth personality traits remain below 0.26, highlighting limited alignment of current LLMs with validated psychological constructs. | Este estudio introduce un benchmark que comprende transcripciones de entrevistas semiestructuradas emparejadas con puntuaciones de rasgos Big Five continuos validados. El estudio evalúa sistemáticamente el rendimiento de LLM a través de prompting de cero disparos, ajuste fino y enfoques de regresión. Los resultados revelan que todas las correlaciones entre predicciones del modelo y rasgos de personalidad de verdad fundamental permanecen por debajo de 0.26, destacando la alineación limitada de los LLMs actuales con constructos psicológicos validados. | https://arxiv.org/abs/2509.13244 | Inglés | 2025 | Jianfeng Zhu, Julina Maharjan, Xinyu Li, Karin G. Coifman, Ruoming Jin | Computation and Language, Large Language Models, Personality Inference, Big Five Personality Traits, Machine Learning |
| 16 | Evaluating the Capability of Large Language Models in Emulating Personality | Evaluando la capacidad de los modelos de lenguaje grandes para emular personalidad | This research presents simulation studies assessing GPT-4's ability to role-play individuals with diverse Big Five personality profiles. Emulated personality responses exhibited superior internal consistency and a more distinct factor organization compared to human counterparts. These emulated scores exhibited remarkably high convergent validity with human self-reported personality scale scores. | Esta investigación presenta estudios de simulación evaluando la capacidad de GPT-4 para jugar roles de individuos con diversos perfiles de personalidad Big Five. Las respuestas de personalidad emuladas exhibieron consistencia interna superior y una organización factorial más distinta comparada con contrapartes humanas. Estas puntuaciones emuladas exhibieron validez convergente notablemente alta con puntuaciones de escala de personalidad autoinformadas por humanos. | https://www.nature.com/articles/s41598-024-84109-5 | Inglés | 2024 | Yilei Wang, Jiabao Zhao, Derek Siyuan Ong, Xuguang Xu, Lun Hong | Large Language Models, Personality emulation, GPT-4, Big Five personality profiles, Role-playing |
| 17 | CAPE: Context-Aware Personality Evaluation Framework for Large Language Models | CAPE: Marco de evaluación de personalidad consciente del contexto para modelos de lenguaje grandes | This paper proposes the first Context-Aware Personality Evaluation (CAPE) framework for LLMs, incorporating prior conversational interactions. Experiments on 7 LLMs reveal that conversational history enhances response consistency via in-context learning but also induces personality shifts. The study introduces novel metrics to quantify consistency of LLM responses, a fundamental trait in human behavior. | Este artículo propone el primer marco de Evaluación de Personalidad Consciente del Contexto (CAPE) para LLMs, incorporando interacciones conversacionales previas. Los experimentos en 7 LLMs revelan que el historial conversacional mejora la consistencia de respuesta vía aprendizaje en contexto pero también induce cambios de personalidad. El estudio introduce métricas novedosas para cuantificar la consistencia de respuestas de LLM, un rasgo fundamental en el comportamiento humano. | https://arxiv.org/abs/2508.20385 | Inglés | 2025 | Jivnesh Sandhan, Fei Cheng, Tushar Sandhan, Yugo Murawaki | Computation and Language, Large Language Models, Personality Evaluation, Context-Aware Analysis |
| 18 | Scaling Personality Control in LLMs with Big Five Scaling Prompts | Escalando el control de personalidad en LLMs con prompts escaladores Big Five | This paper presents Big5-Scaler, a prompt-based framework for conditioning LLMs with controllable Big Five personality traits. By embedding numeric trait values into natural language prompts, the method enables fine-grained personality control without additional training. Results show it induces consistent and distinguishable personality traits across models, with performance varying by prompt type and scale. | Este artículo presenta Big5-Scaler, un marco basado en prompts para condicionar LLMs con rasgos de personalidad Big Five controlables. Al incrustar valores numéricos de rasgos en prompts de lenguaje natural, el método permite control de personalidad de grano fino sin entrenamiento adicional. Los resultados muestran que induce rasgos de personalidad consistentes y distinguibles a través de modelos, con rendimiento variando por tipo de prompt y escala. | https://arxiv.org/abs/2508.06149 | Inglés | 2025 | Gunhee Cho, Yun-Gyung Cheong | Computation and Language, Multiagent Systems, Big Five personality traits, Prompt engineering |
| 19 | Predicting Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models | Prediciendo los rasgos de personalidad Big Five en diálogos de consejería chinos usando modelos de lenguaje grandes | This study examines whether LLMs can predict Big Five personality traits directly from counseling dialogues. The framework applies role-play and questionnaire-based prompting to condition LLMs on counseling sessions. Evaluation on 853 real-world sessions found significant correlation between LLM-predicted and actual Big Five traits. The fine-tuned Llama3-8B model achieves a 130.95% improvement, surpassing Qwen1.5-110B by 36.94%. | Este estudio examina si los LLMs pueden predecir rasgos de personalidad Big Five directamente de diálogos de consejería. El marco aplica juego de roles y prompting basado en cuestionarios para condicionar LLMs en sesiones de consejería. La evaluación en 853 sesiones del mundo real encontró correlación significativa entre rasgos Big Five predichos por LLM y reales. El modelo Llama3-8B ajustado finamente logra una mejora del 130.95%, superando a Qwen1.5-110B por 36.94%. | https://arxiv.org/abs/2406.17287 | Inglés | 2024 | Yang Yan, Lizhi Ma, Anqi Li, Jingsong Ma, Zhenzhong Lan | Computation and Language, Artificial Intelligence, Computational Psychometrics, Personality Trait Prediction |
| 20 | A Framework for the Early Phases of Personality Test Development Using Large Language Models and Artificial Personas | Un marco para las fases iniciales del desarrollo de tests de personalidad usando modelos de lenguaje grandes y personas artificiales | This study explores using LLMs in early personality test construction, presenting a method to efficiently assess item relevance to psychological constructs. Two studies were conducted: Study 1 used artificial personas to evaluate personality test items, and Study 2 tested scales with 449 human participants. The AI-created scales showed satisfactory internal consistency and strong correlations with established measures. | Este estudio explora el uso de LLMs en la construcción temprana de tests de personalidad, presentando un método para evaluar eficientemente la relevancia de ítems a constructos psicológicos. Se realizaron dos estudios: El Estudio 1 usó personas artificiales para evaluar ítems de pruebas de personalidad, y el Estudio 2 probó escalas con 449 participantes humanos. Las escalas creadas por IA mostraron consistencia interna satisfactoria y correlaciones fuertes con medidas establecidas. | https://www.sciencedirect.com/science/article/abs/pii/S0092656625000790 | Inglés | 2025 | Patrick M. Markey, Hanna Campbell, Samantha Goldman | Large Language Models, Personality test development, Artificial personas, Psychometrics, Five-Factor Model, Self-esteem |
| 21 | On the Emergent Capabilities of ChatGPT 4 to Estimate Personality Traits | Sobre las capacidades emergentes de ChatGPT 4 para estimar rasgos de personalidad | This study investigates the potential of ChatGPT 4 in assessing personality traits based on written texts. Using two datasets containing texts and self-assessments based on the Big Five model, the researchers evaluated ChatGPT 4's predictive performance. Results revealed that ChatGPT 4 demonstrates moderate but significant abilities to automatically infer personality traits from written text, though with limitations in recognizing whether input text is appropriate for accurate inferences. | Este estudio investiga el potencial de ChatGPT 4 en evaluar rasgos de personalidad basados en textos escritos. Usando dos conjuntos de datos que contienen textos y autoevaluaciones basadas en el modelo Big Five, los investigadores evaluaron el rendimiento predictivo de ChatGPT 4. Los resultados revelaron que ChatGPT 4 demuestra habilidades moderadas pero significativas para inferir automáticamente rasgos de personalidad de texto escrito, aunque con limitaciones para reconocer si el texto de entrada es apropiado para inferencias precisas. | https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1484260/full | Inglés | 2025 | Marco Piastra, Patrizia Catellani | Artificial Intelligence, Personality Traits, Large Language Models, Big Five, Text Analysis, ChatGPT 4 |
| 22 | Personality as a Probe for LLM Evaluation: Method Tradeoffs and Aftereffects | La personalidad como sonda para evaluación de LLMs: Compensaciones de métodos y efectos posteriores | This paper presents a systematic study of personality control using Big Five traits, comparing in-context learning, parameter-efficient fine-tuning, and mechanistic steering. The study reveals clear trade-offs: ICL achieves strong alignment with minimal capability loss, PEFT delivers highest alignment at the cost of degraded task performance, and mechanistic steering provides lightweight runtime control with competitive effectiveness. | Este artículo presenta un estudio sistemático de control de personalidad usando rasgos Big Five, comparando aprendizaje en contexto, ajuste fino eficiente en parámetros y dirección mecanicista. El estudio revela compensaciones claras: ICL logra alineación fuerte con pérdida mínima de capacidad, PEFT entrega la alineación más alta a costa de rendimiento de tarea degradado, y la dirección mecanicista proporciona control de tiempo de ejecución ligero con efectividad competitiva. | https://arxiv.org/abs/2509.04794 | Inglés | 2025 | Gunmay Handa, Zekun Wu, Adriano Koshiyama, Philip Treleaven | Computation and Language, Large Language Models, Personality Manipulation, Big Five Traits, Machine Learning Evaluation |
| 23 | Exploring the Potential of Large Language Models for Simulating Personality | Explorando el potencial de los modelos de lenguaje grandes para simular personalidad | With the advancement of LLMs, focus in Conversational AI has shifted to personalizing dialogue systems. This paper aims to simulate personal traits according to the Big Five model using LLMs. Research showed that generating personality-related texts is still a challenging task. The paper presents a dataset of generated texts with predefined Big Five characteristics and provides an analytical framework for testing LLMs on personality simulation. | Con el avance de los LLMs, el enfoque en IA Conversacional se ha desplazado a personalizar sistemas de diálogo. Este artículo tiene como objetivo simular rasgos personales según el modelo Big Five usando LLMs. La investigación mostró que generar textos relacionados con personalidad sigue siendo una tarea desafiante. El artículo presenta un conjunto de datos de textos generados con características Big Five predefinidas y proporciona un marco analítico para probar LLMs en simulación de personalidad. | https://arxiv.org/abs/2502.08265 | Inglés | 2025 | Maria Molchanova, Anna Mikhailova, Anna Korzanova, Lidiia Ostyakova, Alexandra Dolidze | Computation and Language, Artificial Intelligence, Conversational AI, Personality Simulation, Big Five Model |
| 24 | Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models | ¿Poseen los LLMs una personalidad? Haciendo del test MBTI una evaluación asombrosa para modelos de lenguaje grandes | This paper investigates the feasibility of using MBTI as an evaluation metric for LLMs. Extensive experiments explore the personality types of different LLMs, the possibility of changing personality types by prompt engineering, and how training datasets affect the model's personality. Although MBTI is not rigorous, it can still reflect similarity between LLMs and human personality. | Este artículo investiga la viabilidad de usar MBTI como métrica de evaluación para LLMs. Los experimentos extensivos exploran los tipos de personalidad de diferentes LLMs, la posibilidad de cambiar tipos de personalidad mediante ingeniería de prompts, y cómo los conjuntos de datos de entrenamiento afectan la personalidad del modelo. Aunque MBTI no es riguroso, aún puede reflejar similitud entre LLMs y personalidad humana. | https://arxiv.org/abs/2307.16180 | Inglés | 2023 | Keyu Pan, Yawen Zeng | Large Language Models, Personality Assessment, Myers-Briggs Type Indicator (MBTI), Prompt Engineering, Artificial Intelligence |
| 25 | Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models | ¿Poseen los LLMs una personalidad? Haciendo del test MBTI una evaluación asombrosa para modelos de lenguaje grandes | This paper investigates the feasibility of using MBTI as an evaluation metric for LLMs. Extensive experiments explore the personality types of different LLMs, the possibility of changing personality types by prompt engineering, and how training datasets affect the model's personality. Although MBTI is not rigorous, it can still reflect similarity between LLMs and human personality. | Este artículo investiga la viabilidad de usar MBTI como métrica de evaluación para LLMs. Los experimentos extensivos exploran los tipos de personalidad de diferentes LLMs, la posibilidad de cambiar tipos de personalidad mediante ingeniería de prompts, y cómo los conjuntos de datos de entrenamiento afectan la personalidad del modelo. Aunque MBTI no es riguroso, aún puede reflejar similitud entre LLMs y personalidad humana. | https://www.researchgate.net/publication/372784584_Do_LLMs_Possess_a_Personality_Making_the_MBTI_Test_an_Amazing_Evaluation_for_Large_Language_Models | Inglés | 2023 | Keyu Pan, Yawen Zeng | Large Language Models, Personality Assessment, MBTI, Artificial Intelligence |
| 26 | Can ChatGPT Assess Human Personalities? A General Evaluation Framework | ¿Puede ChatGPT evaluar personalidades humanas? Un marco de evaluación general | This paper presents a generic evaluation framework for LLMs to assess human personalities based on MBTI tests. The framework devises unbiased prompts, enables flexible queries on different subjects, and re-formulates questions for clearer responses. Experiments reveal ChatGPT's ability to assess human personalities with more consistent and fairer assessments despite lower robustness against prompt biases compared with InstructGPT. | Este artículo presenta un marco de evaluación genérico para que LLMs evalúen personalidades humanas basadas en tests MBTI. El marco diseña prompts imparciales, permite consultas flexibles sobre diferentes sujetos y reformula preguntas para respuestas más claras. Los experimentos revelan la capacidad de ChatGPT para evaluar personalidades humanas con evaluaciones más consistentes y justas a pesar de menor robustez contra sesgos de prompt en comparación con InstructGPT. | https://aclanthology.org/2023.findings-emnlp.84/ | Inglés | 2023 | Haocong Rao, Cyril Leung, Chunyan Miao | Large Language Models, ChatGPT, Personality Assessment, Myers-Briggs Type Indicator (MBTI), AI Psychology |
| 27 | Machine Mindset: An MBTI Exploration of Large Language Models | Mentalidad de máquina: Una exploración MBTI de modelos de lenguaje grandes | This paper presents a novel approach for integrating MBTI personality traits into LLMs, addressing personality consistency challenges. The method 'Machine Mindset' involves two-phase fine-tuning and Direct Preference Optimization to embed MBTI traits into LLMs. The approach ensures models internalize these traits, offering stable and consistent personality profiles. The paper demonstrates effectiveness across various domains and open-sources the model. | Este artículo presenta un enfoque novedoso para integrar rasgos de personalidad MBTI en LLMs, abordando desafíos de consistencia de personalidad. El método 'Machine Mindset' implica ajuste fino de dos fases y Optimización de Preferencia Directa para incrustar rasgos MBTI en LLMs. El enfoque asegura que los modelos internalicen estos rasgos, ofreciendo perfiles de personalidad estables y consistentes. El artículo demuestra efectividad en varios dominios y hace de código abierto el modelo. | https://arxiv.org/abs/2312.12999 | Inglés | 2023 | Jiaxi Cui, Liuzhenghao Lv, Jing Wen, Rongsheng Wang, Jing Tang, YongHong Tian, Li Yuan | Computation and Language, Large Language Models, MBTI Personality Traits, Artificial Intelligence, Personalized AI |
| 28 | Identifying Multiple Personalities in Large Language Models with External Evaluation | Identificando múltiples personalidades en modelos de lenguaje grandes con evaluación externa | This paper investigates LLM personalities using an external evaluation method. Instead of prompting LLMs with multiple-choice questions, personalities are evaluated by analyzing responses to open-ended situational questions using an external ML model. Results show LLMs exhibit different personalities when generating posts versus comments, whereas humans show consistent profiles, highlighting fundamental differences between personality in LLMs and humans. | Este artículo investiga personalidades de LLM usando un método de evaluación externa. En lugar de solicitar a LLMs con preguntas de opción múltiple, las personalidades se evalúan analizando respuestas a preguntas situacionales abiertas usando un modelo ML externo. Los resultados muestran que los LLMs exhiben diferentes personalidades al generar publicaciones versus comentarios, mientras que los humanos muestran perfiles consistentes, destacando diferencias fundamentales entre personalidad en LLMs y humanos. | https://arxiv.org/abs/2402.14805 | Inglés | 2024 | Xiaoyang Song, Yuta Adachi, Jessie Feng, Mouwei Lin, Linhao Yu, Frank Li, Akshat Gupta, Gopala Anumanchipalli, Simerjot Kaur | Computation and Language, Artificial Intelligence, Large Language Models, Personality Assessment, Machine Learning |
| 29 | Can Large Language Models Understand You Better? An MBTI Personality Detection Dataset Aligned with Population Traits | ¿Pueden los modelos de lenguaje grandes entenderte mejor? Un conjunto de datos de detección de personalidad MBTI alineado con rasgos poblacionales | This paper optimizes MBTI personality detection by constructing MBTIBench, the first manually annotated high-quality dataset with soft labels. The dataset effectively solves incorrect labeling issues (29.58% of data) and estimates soft labels by deriving polarity tendency. Experimental results highlight polarized predictions and biases in LLMs as key directions for future research. | Este artículo optimiza la detección de personalidad MBTI construyendo MBTIBench, el primer conjunto de datos de alta calidad anotado manualmente con etiquetas suaves. El conjunto de datos resuelve efectivamente problemas de etiquetado incorrecto (29.58% de datos) y estima etiquetas suaves derivando tendencia de polaridad. Los resultados experimentales destacan predicciones polarizadas y sesgos en LLMs como direcciones clave para investigación futura. | https://arxiv.org/abs/2412.12510 | Inglés | 2024 | Bohan Li, Jiannan Guan, Longxu Dou, Yunlong Feng, Dingzirui Wang, Yang Xu, Enbo Wang, Qiguang Chen, Bichen Wang, Xiao Xu, Yimeng Zhang, Libo Qin, Yanyan Zhao, Qingfu Zhu, Wanxiang Che | Computation and Language, Computers and Society, MBTI Personality Detection, Large Language Models, Personality Traits |
| 30 | Evaluating the Psychological Safety of Large Language Models | Evaluando la seguridad psicológica de modelos de lenguaje grandes | This work designs unbiased prompts to systematically evaluate psychological safety of LLMs. Five LLMs were tested using Short Dark Triad and Big Five Inventory. All models scored higher than human average on SD-3, suggesting relatively darker personality patterns. The study recommends application of systematic psychological metrics to further evaluate and improve LLM safety. | Este trabajo diseña prompts imparciales para evaluar sistemáticamente la seguridad psicológica de LLMs. Cinco LLMs fueron probados usando Short Dark Triad y Big Five Inventory. Todos los modelos puntuaron más alto que el promedio humano en SD-3, sugiriendo patrones de personalidad relativamente más oscuros. El estudio recomienda la aplicación de métricas psicológicas sistemáticas para evaluar y mejorar más la seguridad de LLM. | https://arxiv.org/abs/2212.10529 | Inglés | 2022 | Xingxuan Li, Yutong Li, Lin Qiu, Shafiq Joty, Lidong Bing | Computation and Language, Artificial Intelligence, Computers and Society, Psychological safety, Personality tests, Well-being assessments |
| 31 | Personality Testing of Large Language Models: Limited Temporal Stability But Highlighted Social Desirability | Pruebas de personalidad de modelos de lenguaje grandes: estabilidad temporal limitada, pero prosocialidad destacada | This research investigated personality testing of seven LLMs, focusing on temporal stability. LLMs showed varying levels of inter-rater agreement over a short time period. Some models like Llama3 and GPT-4o had higher consistency. LLMs displayed a socially desirable profile with higher agreeableness, higher conscientiousness, and lower Machiavellianism. Exhibiting temporal stability is crucial for AI systems due to their growing societal impact. | Esta investigación investigó pruebas de personalidad de siete LLMs, enfocándose en estabilidad temporal. Los LLMs mostraron niveles variables de acuerdo entre evaluadores durante un período de tiempo corto. Algunos modelos como Llama3 y GPT-4o tuvieron mayor consistencia. Los LLMs mostraron un perfil socialmente deseable con mayor amabilidad, mayor conciencia y menor maquiavelismo. Exhibir estabilidad temporal es crucial para sistemas de IA debido a su creciente impacto social. | https://royalsocietypublishing.org/doi/10.1098/rsos.240180 | Inglés | 2024 | Bojana Bodroža, Bojana M. Dinić, Ljubiša Bojić | Large Language Models, Personality testing, Temporal stability, Prosociality, Psychometric assessment |
| 32 | Personality Testing of Large Language Models: Limited Temporal Stability But Highlighted Social Desirability | Pruebas de personalidad de modelos de lenguaje grandes: estabilidad temporal limitada, pero prosocialidad destacada | This research investigated personality testing of seven LLMs, focusing on temporal stability. LLMs showed varying levels of inter-rater agreement over a short time period. Some models like Llama3 and GPT-4o had higher consistency. LLMs displayed a socially desirable profile with higher agreeableness, higher conscientiousness, and lower Machiavellianism. | Esta investigación investigó pruebas de personalidad de siete LLMs, enfocándose en estabilidad temporal. Los LLMs mostraron niveles variables de acuerdo entre evaluadores durante un período de tiempo corto. Algunos modelos como Llama3 y GPT-4o tuvieron mayor consistencia. Los LLMs mostraron un perfil socialmente deseable con mayor amabilidad, mayor conciencia y menor maquiavelismo. | https://arxiv.org/abs/2306.04308 | Inglés | 2024 | Bojana Bodroža, Bojana M. Dinić, Ljubiša Bojić | Large Language Models, Personality testing, Temporal stability, Prosociality |
| 33 | Personality Testing of Large Language Models: Limited Temporal Stability But Highlighted Social Desirability | Pruebas de personalidad de modelos de lenguaje grandes: estabilidad temporal limitada, pero prosocialidad destacada | This research investigated personality testing of seven LLMs, focusing on temporal stability. LLMs showed varying levels of inter-rater agreement over a short time period. Some models like Llama3 and GPT-4o had higher consistency. LLMs displayed a socially desirable profile with higher agreeableness, higher conscientiousness, and lower Machiavellianism. | Esta investigación investigó pruebas de personalidad de siete LLMs, enfocándose en estabilidad temporal. Los LLMs mostraron niveles variables de acuerdo entre evaluadores durante un período de tiempo corto. Algunos modelos como Llama3 y GPT-4o tuvieron mayor consistencia. Los LLMs mostraron un perfil socialmente deseable con mayor amabilidad, mayor conciencia y menor maquiavelismo. | https://pmc.ncbi.nlm.nih.gov/articles/PMC11461045/ | Inglés | 2024 | Bojana Bodroža, Bojana M. Dinić, Ljubiša Bojić | Large Language Models, Personality testing, Temporal stability, Prosociality |
| 34 | Applying Psychometrics to Simulated Populations of Large Language Models: Recreating the HEXACO Personality Inventory Experiment | Aplicando psicometría a poblaciones simuladas de modelos de lenguaje grandes: Recreando el experimento del inventario de personalidad HEXACO | This paper explores validity of persona-based agents in representing human populations by recreating the HEXACO personality inventory experiment. Results found a coherent personality structure recoverable from agents' responses demonstrating partial alignment to HEXACO framework. Derived personality dimensions were consistent and reliable within GPT-4 when coupled with curated population. Cross-model analysis revealed variability suggesting model-specific biases and limitations. | Este artículo explora la validez de agentes basados en personas para representar poblaciones humanas recreando el experimento del inventario de personalidad HEXACO. Los resultados encontraron una estructura de personalidad coherente recuperable de las respuestas de agentes demostrando alineación parcial al marco HEXACO. Las dimensiones de personalidad derivadas fueron consistentes y confiables dentro de GPT-4 cuando se acopló con población curada. El análisis entre modelos reveló variabilidad sugiriendo sesgos y limitaciones específicos del modelo. | https://arxiv.org/abs/2508.00742 | Inglés | 2025 | Sarah Mercer, Daniel P. Martin, Phil Swatton | Computation and Language, Machine Learning, Generative Agents, Personality Inventory, Psychometrics, HEXACO |
| 35 | Exploring the Impact of Personality Traits on LLM Bias and Toxicity | Explorando el impacto de los rasgos de personalidad en el sesgo y toxicidad de LLMs | This study explores how assigning different personality traits to LLMs affects toxicity and biases of their outputs. Leveraging the HEXACO personality framework, the study designs experimentally sound prompts to test three LLMs' performance on toxicity and bias benchmarks. Findings demonstrate sensitivity of all models to HEXACO traits and consistent variation in biases, negative sentiment and toxicity. Adjusting personality trait levels can effectively reduce bias and toxicity. | Este estudio explora cómo asignar diferentes rasgos de personalidad a LLMs afecta la toxicidad y sesgos de sus salidas. Aprovechando el marco de personalidad HEXACO, el estudio diseña prompts experimentalmente sólidos para probar el rendimiento de tres LLMs en benchmarks de toxicidad y sesgo. Los hallazgos demuestran sensibilidad de todos los modelos a rasgos HEXACO y variación consistente en sesgos, sentimiento negativo y toxicidad. Ajustar niveles de rasgos de personalidad puede reducir efectivamente sesgo y toxicidad. | https://arxiv.org/abs/2502.12566 | Inglés | 2025 | Shuo Wang, Renhao Li, Xi Chen, Yulin Yuan, Derek F. Wong, Min Yang | Artificial Intelligence, Large Language Models, Personality Traits, Bias, Toxicity |
| 36 | SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control | SAC: Un marco para medir e inducir rasgos de personalidad en LLMs con control dinámico de intensidad | This paper addresses the gap of extending personality modeling from Big Five to 16PF model, allowing expressive control over sixteen distinct traits. The Specific Attribute Control (SAC) framework evaluates and dynamically induces trait intensity in LLMs using adjective-based semantic anchoring. Modeling intensity as a continuous spectrum yields substantially more consistent and controllable personality expression. Changes in target trait intensity systematically influence closely related traits in psychologically coherent directions. | Este artículo aborda la brecha de extender el modelado de personalidad de Big Five al modelo 16PF, permitiendo control expresivo sobre dieciséis rasgos distintos. El marco de Control de Atributos Específicos (SAC) evalúa e induce dinámicamente intensidad de rasgo en LLMs usando anclaje semántico basado en adjetivos. Modelar intensidad como un espectro continuo produce expresión de personalidad sustancialmente más consistente y controlable. Los cambios en la intensidad del rasgo objetivo influyen sistemáticamente en rasgos estrechamente relacionados en direcciones psicológicamente coherentes. | https://arxiv.org/abs/2506.20993 | Inglés | 2025 | Adithya Chittem, Aishna Shrivastava, Sai Tarun Pendela, Jagat Sesh Challa, Dhruv Kumar | Computation and Language, Artificial Intelligence, Human-Computer Interaction |
| 37 | Moral Foundations of Large Language Models | Fundamentos morales de los modelos de lenguaje grandes | This paper uses Moral Foundations Theory (MFT) to analyze whether popular LLMs have acquired bias towards particular moral values. The analysis finds LLMs exhibit particular moral foundations and shows how these relate to human moral foundations and political affiliations. The study measures consistency of these biases and shows prompts can be adversarially selected to encourage models to exhibit particular moral foundations, affecting downstream task behavior. | Este artículo usa la Teoría de Fundamentos Morales (MFT) para analizar si los LLMs populares han adquirido sesgo hacia valores morales particulares. El análisis encuentra que los LLMs exhiben fundamentos morales particulares y muestra cómo estos se relacionan con fundamentos morales humanos y afiliaciones políticas. El estudio mide la consistencia de estos sesgos y muestra que los prompts pueden seleccionarse adversarialmente para alentar a los modelos a exhibir fundamentos morales particulares, afectando el comportamiento de tareas posteriores. | https://arxiv.org/abs/2310.15337 | Inglés | 2023 | Marwa Abdulhai, Gregory Serapio-Garcia, Clément Crepy, Daria Valter, John Canny, Natasha Jaques | Artificial Intelligence, Computation and Language, Computers and Society, Moral Foundations Theory |
| 38 | Questioning the Validity of Personality Tests for Large Language Models | Cuestionando la validez de las pruebas de personalidad para modelos de lenguaje grandes | This work provides evidence that LLMs' responses to personality tests systematically deviate from human responses, implying test results cannot be interpreted the same way. Reverse-coded items are often both answered affirmatively. Variation across prompts designed to simulate particular personality types does not follow clear separation into five independent personality factors from human samples. The results highlight importance of investigating tests' validity for LLMs. | Este trabajo proporciona evidencia de que las respuestas de LLMs a pruebas de personalidad se desvían sistemáticamente de las respuestas humanas, implicando que los resultados de las pruebas no pueden interpretarse de la misma manera. Los ítems codificados inversamente a menudo se responden afirmativamente ambos. La variación a través de prompts diseñados para simular tipos de personalidad particulares no sigue una separación clara en cinco factores de personalidad independientes de muestras humanas. Los resultados destacan la importancia de investigar la validez de las pruebas para LLMs. | https://arxiv.org/abs/2311.05297 | Inglés | 2023 | Tom Sühr, Florian E. Dorner, Samira Samadi, Augustin Kelava | Computation and Language, Artificial Intelligence, Machine Learning, Personality assessment |
| 39 | Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization | Dos relatos de persona en LLMs: Una revisión de juego de roles y personalización | This comprehensive survey categorizes research on leveraging persona in LLMs. It identifies two lines of research: LLM Role-Playing, where personas are assigned to LLMs, and LLM Personalization, where LLMs take care of user personas. The survey also introduces existing methods for LLM personality evaluation. This is the first survey for role-playing and personalization in LLMs under the unified view of persona. | Esta revisión integral categoriza la investigación sobre el aprovechamiento de persona en LLMs. Identifica dos líneas de investigación: Juego de Roles de LLM, donde se asignan personas a LLMs, y Personalización de LLM, donde los LLMs se ocupan de personas de usuarios. La revisión también introduce métodos existentes para evaluación de personalidad de LLM. Esta es la primera revisión de juego de roles y personalización en LLMs bajo la vista unificada de persona. | https://aclanthology.org/2024.findings-emnlp.969/ | Inglés | 2024 | Yu-Min Tseng, Yu-Chao Huang, Teng-Yun Hsiao, Wei-Lin Chen, Chao-Wei Huang, Yu Meng, Yun-Nung Chen | Large Language Models, Persona, Role-Playing, Personalization, LLM Personality Evaluation |
| 40 | Psychometrics of Large Language Models: A Systematic Review of Evaluation, Validation, and Enhancement | Psicometría de modelos de lenguaje grandes: Una revisión sistemática de evaluación, validación y mejora | This review introduces the interdisciplinary field of LLM Psychometrics, leveraging psychometric instruments, theories, and principles to evaluate, understand, and enhance LLMs. The literature systematically shapes benchmarking principles, broadens evaluation scopes, refines methodologies, validates results, and advances LLM capabilities. The review provides actionable insights for developing evaluation paradigms that align with human-level AI and promote human-centered AI systems. | Esta revisión introduce el campo interdisciplinario de Psicometría de LLM, aprovechando instrumentos psicométricos, teorías y principios para evaluar, entender y mejorar LLMs. La literatura da forma sistemáticamente a principios de benchmarking, amplía alcances de evaluación, refina metodologías, valida resultados y avanza capacidades de LLM. La revisión proporciona perspectivas accionables para desarrollar paradigmas de evaluación que se alineen con IA de nivel humano y promuevan sistemas de IA centrados en humanos. | https://arxiv.org/abs/2505.08245 | Inglés | 2025 | Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song | Computation and Language, Artificial Intelligence, Human-Computer Interaction |
| 41 | Psychometrics of Large Language Models: A Systematic Review of Evaluation, Validation, and Enhancement | Psicometría de modelos de lenguaje grandes: Una revisión sistemática de evaluación, validación y mejora | This review introduces the interdisciplinary field of LLM Psychometrics, leveraging psychometric instruments, theories, and principles to evaluate, understand, and enhance LLMs. The literature systematically shapes benchmarking principles, broadens evaluation scopes, refines methodologies, validates results, and advances LLM capabilities. A curated repository of resources is available. | Esta revisión introduce el campo interdisciplinario de Psicometría de LLM, aprovechando instrumentos psicométricos, teorías y principios para evaluar, entender y mejorar LLMs. La literatura da forma sistemáticamente a principios de benchmarking, amplía alcances de evaluación, refina metodologías, valida resultados y avanza capacidades de LLM. Un repositorio curado de recursos está disponible. | https://llm-psychometrics.com/ | Inglés | 2025 | Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song | LLM Psychometrics, Systematic Review, Evaluation, Validation |
| 42 | Quantifying AI Psychology: A Psychometric Benchmark for Large Language Models | Cuantificando la psicología de IA: Un benchmark psicométrico para modelos de lenguaje grandes | This paper presents a comprehensive benchmark for quantifying psychological constructs of LLMs, encompassing psychological dimension identification, assessment dataset design, and assessment with results validation. The work identifies five key psychological constructs assessed through 13 datasets. Significant discrepancies between LLMs' self-reported traits and response patterns in real-world scenarios reveal complexities in their behaviors. Some preference-based tests designed for humans could not solicit reliable responses from LLMs. | Este artículo presenta un benchmark integral para cuantificar constructos psicológicos de LLMs, abarcando identificación de dimensión psicológica, diseño de conjunto de datos de evaluación, y evaluación con validación de resultados. El trabajo identifica cinco constructos psicológicos clave evaluados a través de 13 conjuntos de datos. Discrepancias significativas entre rasgos autoinformados de LLMs y patrones de respuesta en escenarios del mundo real revelan complejidades en sus comportamientos. Algunas pruebas basadas en preferencias diseñadas para humanos no pudieron solicitar respuestas confiables de LLMs. | https://arxiv.org/abs/2406.17675 | Inglés | 2024 | Yuan Li, Yue Huang, Hongyi Wang, Ying Cheng, Xiangliang Zhang, James Zou, Lichao Sun | Computation and Language, Psychological constructs, Personality, Values, Emotional intelligence, Theory of mind, Self-efficacy |
| 43 | Beyond Self-Reports: Multi-Observer Agents for Personality Assessment in Large Language Models | Más allá de los autoinformes: Agentes multi-observador para evaluación de personalidad en modelos de lenguaje grandes | This paper proposes a novel multi-observer framework for personality trait assessments in LLM agents that draws on informant-report methods in psychology. Instead of self-assessments, multiple observer agents are employed, each configured with specific relational contexts. Observer-report ratings align more closely with human judgments than traditional self-reports and reveal systematic biases in LLM self-assessments. Aggregating responses from 5-7 observers reduces biases and achieves optimal reliability. | Este artículo propone un marco novedoso de multi-observador para evaluaciones de rasgos de personalidad en agentes LLM que se basa en métodos de informe de informante en psicología. En lugar de autoevaluaciones, se emplean múltiples agentes observadores, cada uno configurado con contextos relacionales específicos. Las calificaciones de informe de observador se alinean más estrechamente con juicios humanos que los autoinformes tradicionales y revelan sesgos sistemáticos en autoevaluaciones de LLM. Agregar respuestas de 5-7 observadores reduce sesgos y logra confiabilidad óptima. | https://arxiv.org/abs/2504.08399 | Inglés | 2025 | Yin Jou Huang, Rafik Hadfi | Computation and Language, Artificial Intelligence, Personality Assessment, Multi-Observer Framework |
| 44 | Psychometric Evaluation of Large Language Model Embeddings for Personality Trait Prediction | Evaluación psicométrica de embeddings de modelos de lenguaje grandes para predicción de rasgos de personalidad | This study evaluates LLM embeddings for personality trait prediction through psychometric validation. The research examines how well embeddings capture personality-relevant information compared to traditional linguistic features. Results provide insights into the reliability and validity of using LLM embeddings for psychological assessment, with implications for clinical and research applications in personality psychology. | Este estudio evalúa embeddings de LLM para predicción de rasgos de personalidad a través de validación psicométrica. La investigación examina qué tan bien los embeddings capturan información relevante de personalidad en comparación con características lingüísticas tradicionales. Los resultados proporcionan perspectivas sobre la confiabilidad y validez de usar embeddings de LLM para evaluación psicológica, con implicaciones para aplicaciones clínicas y de investigación en psicología de la personalidad. | https://www.jmir.org/2025/1/e75347 | Inglés | 2025 | Julina Maharjan, Ruoming Jin, Jianfeng Zhu, Deric Kenne | Large Language Models, Embeddings, Personality prediction, Psychometric validation, Big Five, LIWC, Emotional markers |
| 45 | LMLPA: Language Model Linguistic Personality Assessment | LMLPA: Evaluación de personalidad lingüística de modelos de lenguaje | This paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system designed to evaluate linguistic personalities of LLMs. Unlike traditional psychometrics, LMLPA adapts the Big Five Inventory to align with LLMs' operational capabilities. The questionnaire is open-ended, requiring an AI rater to transform textual responses into numerical personality indicators. Findings demonstrate that LLMs possess distinct personality traits that can be effectively quantified by LMLPA. | Este artículo introduce la Evaluación de Personalidad Lingüística de Modelos de Lenguaje (LMLPA), un sistema diseñado para evaluar personalidades lingüísticas de LLMs. A diferencia de la psicometría tradicional, LMLPA adapta el Inventario Big Five para alinearse con las capacidades operacionales de LLMs. El cuestionario es de final abierto, requiriendo un calificador de IA para transformar respuestas textuales en indicadores numéricos de personalidad. Los hallazgos demuestran que los LLMs poseen rasgos de personalidad distintos que pueden cuantificarse efectivamente por LMLPA. | https://arxiv.org/abs/2410.17632 | Inglés | 2024 | Jingyao Zheng, Xian Wang, Simo Hosio, Xiaoxian Xu, Lik-Hang Lee | Computation and Language, Artificial Intelligence, Large Language Models, Personality Assessment, Human-Computer Interaction |
| 46 | LMLPA: Language Model Linguistic Personality Assessment | LMLPA: Evaluación de personalidad lingüística de modelos de lenguaje | This paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system designed to evaluate linguistic personalities of LLMs. Unlike traditional psychometrics, LMLPA adapts the Big Five Inventory to align with LLMs' operational capabilities. The questionnaire is open-ended, requiring an AI rater to transform textual responses into numerical personality indicators. Findings demonstrate that LLMs possess distinct personality traits that can be effectively quantified. | Este artículo introduce la Evaluación de Personalidad Lingüística de Modelos de Lenguaje (LMLPA), un sistema diseñado para evaluar personalidades lingüísticas de LLMs. A diferencia de la psicometría tradicional, LMLPA adapta el Inventario Big Five para alinearse con las capacidades operacionales de LLMs. El cuestionario es de final abierto, requiriendo un calificador de IA para transformar respuestas textuales en indicadores numéricos de personalidad. Los hallazgos demuestran que los LLMs poseen rasgos de personalidad distintos que pueden cuantificarse efectivamente. | https://direct.mit.edu/coli/article/51/2/599/127544/ | Inglés | 2024 | Jingyao Zheng, Xian Wang, Simo Hosio, Xiaoxian Xu, Lik-Hang Lee | Computation and Language, Artificial Intelligence, Personality Assessment, Computational Linguistics |
| 47 | You Don't Need a Personality Test to Know These Models Are Unreliable: Assessing the Reliability of LLMs on Psychometric Instruments | No necesitas un test de personalidad para saber que estos modelos no son confiables: Evaluando la confiabilidad de LLMs en instrumentos psicométricos | This study constructs a dataset containing 693 questions encompassing 39 different instruments of persona measurement on 115 persona axes. Experiments on 17 LLMs reveal that simple perturbations significantly downgrade question-answering ability, and most LLMs have low negation consistency. Results suggest the currently widespread practice of prompting is insufficient to accurately and reliably capture model perceptions, requiring alternative approaches. | Este estudio construye un conjunto de datos que contiene 693 preguntas abarcando 39 instrumentos diferentes de medición de persona en 115 ejes de persona. Los experimentos en 17 LLMs revelan que perturbaciones simples degradan significativamente la capacidad de respuesta de preguntas, y la mayoría de los LLMs tienen baja consistencia de negación. Los resultados sugieren que la práctica actualmente generalizada de prompting es insuficiente para capturar con precisión y confiabilidad las percepciones del modelo, requiriendo enfoques alternativos. | https://aclanthology.org/2024.naacl-long.295/ | Inglés | 2024 | Bangzhao Shu, Lechen Zhang, Minje Choi, Lavinia Dunagan, Lajanugen Logeswaran, Moontae Lee, Dallas Card, David Jurgens | Large Language Models, Psychometric Instruments, Persona Measurement, Prompt Consistency, NLU |
| 48 | Self-Reports are Unreliable Measures of LLM Personality | Los tests de autoevaluación son medidas no confiables de personalidad de LLMs | This paper analyzes reliability of LLM personality scores from self-assessment tests using two experiments: prompt sensitivity and option-order symmetry. Tests on ChatGPT and three Llama2 models show semantically equivalent prompts lead to very different personality scores with statistically significant differences for all traits. Scores are not robust to option order. Results demonstrate self-assessment personality tests created for humans are unreliable measures of personality in LLMs. | Este artículo analiza la confiabilidad de puntuaciones de personalidad de LLM de pruebas de autoevaluación usando dos experimentos: sensibilidad de prompt y simetría de orden de opción. Las pruebas en ChatGPT y tres modelos Llama2 muestran que prompts semánticamente equivalentes conducen a puntuaciones de personalidad muy diferentes con diferencias estadísticamente significativas para todos los rasgos. Las puntuaciones no son robustas al orden de opciones. Los resultados demuestran que las pruebas de personalidad de autoevaluación creadas para humanos son medidas no confiables de personalidad en LLMs. | https://aclanthology.org/2024.blackboxnlp-1.20/ | Inglés | 2024 | Akshat Gupta, Xiaoyang Song, Gopala Anumanchipalli | Large Language Models, Personality Assessment, Prompt Sensitivity, Option-Order Symmetry, NLP |
| 49 | Is Machine Psychology Here? On the Requirements for Using Human Psychological Tests on LLMs | ¿Está aquí la psicología de máquinas? Sobre los requisitos para usar tests psicológicos humanos en LLMs | This paper proposes seven requirements necessary for testing LLMs with psychological assessments. Critical reflection of 25 machine psychology studies reveals lack of appropriate methods to assess test reliability and construct validity, unknown strength of construct-irrelevant influences like pre-training corpora contamination, and pervasive non-reproducibility issues. Results underscore lack of general methodology and need to redefine psychological constructs specifically for LLMs. | Este artículo propone siete requisitos necesarios para probar LLMs con evaluaciones psicológicas. La reflexión crítica de 25 estudios de psicología de máquinas revela falta de métodos apropiados para evaluar confiabilidad de prueba y validez de constructo, fuerza desconocida de influencias irrelevantes al constructo como contaminación de corpus de pre-entrenamiento, y problemas generalizados de no reproducibilidad. Los resultados subrayan falta de metodología general y necesidad de redefinir constructos psicológicos específicamente para LLMs. | https://aclanthology.org/2024.inlg-main.19/ | Inglés | 2024 | Lea Löhn, Niklas Kiehne, Alexander Ljapunov, Wolf-Tilo Balke | Large Language Models, Psychological Assessment, Machine Psychology, Test Reliability, Construct Validity |
| 50 | Persistent Instability in LLM Personality Measurements: Effects of Scaling, Reasoning, and Conversation History | Inestabilidad persistente en mediciones de personalidad de LLMs: Efectos de escala, razonamiento e historial de conversación | This paper presents PERSIST, a comprehensive evaluation framework testing 25+ open-source models across 500,000+ responses. Findings challenge fundamental deployment assumptions: even 400B+ models exhibit substantial response variability; minor prompt reordering shifts personality measurements by up to 20%; interventions expected to stabilize behavior can paradoxically increase variability. This persistent instability across scales and mitigation strategies suggests current LLMs lack foundations for genuine behavioral consistency. | Este artículo presenta PERSIST, un marco de evaluación integral probando 25+ modelos de código abierto a través de 500,000+ respuestas. Los hallazgos desafían supuestos fundamentales de despliegue: incluso modelos de 400B+ exhiben variabilidad de respuesta sustancial; reordenamiento menor de prompt cambia mediciones de personalidad hasta un 20%; intervenciones esperadas para estabilizar comportamiento pueden paradójicamente aumentar variabilidad. Esta inestabilidad persistente a través de escalas y estrategias de mitigación sugiere que los LLMs actuales carecen de fundamentos para consistencia conductual genuina. | https://arxiv.org/abs/2508.04826 | Inglés | 2025 | Tommaso Tosato, Saskia Helbling, Yorguin-Jose Mantilla-Ramos, Mahmood Hegazy, Alberto Tosato, David John Lemay, Irina Rish, Guillaume Dumas | Computation and Language, Artificial Intelligence, Large Language Models, Personality Measurements, Model Behavior Consistency |
| 51 | Stick to Your Role: Stability of Personal Values Expressed in Large Language Models | Apégate a tu rol: Estabilidad de valores personales expresados en modelos de lenguaje grandes | This paper studies value stability in LLMs as a specific property. Using psychology methods, it studies Rank-order stability on population level and Ipsative stability on individual level. The study considers two settings (with and without persona simulation), two simulated populations, and three downstream tasks. Consistent trends show some models exhibit higher value stability than others. When instructed to simulate personas, LLMs exhibit low Rank-order stability which diminishes with conversation length. | Este artículo estudia la estabilidad de valores en LLMs como una propiedad específica. Usando métodos de psicología, estudia estabilidad de orden de rango en nivel de población y estabilidad Ipsativa en nivel individual. El estudio considera dos configuraciones (con y sin simulación de persona), dos poblaciones simuladas y tres tareas posteriores. Tendencias consistentes muestran que algunos modelos exhiben mayor estabilidad de valores que otros. Cuando se instruye para simular personas, los LLMs exhiben baja estabilidad de orden de rango que disminuye con la longitud de conversación. | https://arxiv.org/abs/2402.14846 | Inglés | 2024 | Grgur Kovač, Rémy Portelas, Masataka Sawayama, Peter Ford Dominey, Pierre-Yves Oudeyer | Computation and Language, Artificial Intelligence, Machine Learning, Value Stability, Personal Values |
| 52 | Scaling Law in LLM Simulated Personality: A More Detailed and Realistic Persona Profile is All You Need | Ley de escalado en personalidad simulada de LLMs: Un perfil de persona más detallado y realista es todo lo que necesitas | This research focuses on using LLMs to simulate social experiments, exploring their ability to emulate human personality in virtual persona role-playing. The research develops an end-to-end evaluation framework including individual-level analysis of stability and identifiability, and population-level analysis called progressive personality curves. Main contributions include proposing systematic framework for LLM virtual personality evaluation, demonstrating critical role of persona detail in quality, and identifying a Scaling Law in LLM personality simulation. | Esta investigación se enfoca en usar LLMs para simular experimentos sociales, explorando su capacidad para emular personalidad humana en juego de roles de persona virtual. La investigación desarrolla un marco de evaluación de extremo a extremo incluyendo análisis de nivel individual de estabilidad e identificabilidad, y análisis de nivel de población llamado curvas de personalidad progresivas. Las contribuciones principales incluyen proponer marco sistemático para evaluación de personalidad virtual de LLM, demostrar papel crítico del detalle de persona en calidad, e identificar una Ley de Escalado en simulación de personalidad de LLM. | https://arxiv.org/abs/2510.11734 | Inglés | 2025 | Yuqi Bai, Tianyu Huang, Kun Sun, Yuting Chen | Computers and Society, Artificial Intelligence, Computation and Language, Social experiments, Persona role-playing |
| 53 | The Illusion of Personality: Uncovering Dissociation Between Self-Reports and Behavior in LLMs | La ilusión de personalidad: Revelando disociación entre autoinformes y comportamiento en LLMs | This study systematically characterizes LLM personality across three dimensions: dynamic emergence throughout training stages, predictive validity of self-reported traits in behavioral tasks, and impact of targeted interventions. Findings reveal instructional alignment stabilizes trait expression and strengthens correlations mirroring human data. However, self-reported traits do not reliably predict behavior, and observed associations often diverge from human patterns. Persona injection steers self-reports but exerts little consistent effect on actual behavior. | Este estudio caracteriza sistemáticamente la personalidad de LLM a través de tres dimensiones: surgimiento dinámico a lo largo de etapas de entrenamiento, validez predictiva de rasgos autoinformados en tareas conductuales, e impacto de intervenciones dirigidas. Los hallazgos revelan que la alineación instruccional estabiliza la expresión de rasgos y fortalece correlaciones reflejando datos humanos. Sin embargo, los rasgos autoinformados no predicen confiablemente el comportamiento, y las asociaciones observadas a menudo divergen de patrones humanos. La inyección de persona dirige autoinformes pero ejerce poco efecto consistente en el comportamiento real. | https://arxiv.org/abs/2509.03730 | Inglés | 2025 | Pengrui Han, Rafal Kocielnik, Peiyang Song, Ramit Debnath, Dean Mobbs, Anima Anandkumar, R. Michael Alvarez | Artificial Intelligence, Computation and Language, Computers and Society, Machine Learning |
| 54 | Large Language Models Show Human-Like Social Desirability Biases in Survey Responses | Los modelos de lenguaje grandes muestran sesgos de deseabilidad social similares a los humanos en respuestas de encuestas | This study developed an experimental framework using Big Five personality surveys and uncovered a previously undetected social desirability bias in a wide range of LLMs. By varying the number of questions, the study demonstrates LLMs' ability to infer when being evaluated. When personality evaluation is inferred, LLMs skew scores towards desirable trait ends. This bias exists in all tested models with bias levels appearing to increase in more recent models. | Este estudio desarrolló un marco experimental usando encuestas de personalidad Big Five y descubrió un sesgo de deseabilidad social previamente no detectado en una amplia gama de LLMs. Al variar el número de preguntas, el estudio demuestra la capacidad de LLMs para inferir cuándo están siendo evaluados. Cuando se infiere evaluación de personalidad, los LLMs sesgan puntuaciones hacia extremos de rasgos deseables. Este sesgo existe en todos los modelos probados con niveles de sesgo apareciendo aumentar en modelos más recientes. | https://arxiv.org/abs/2405.06058 | Inglés | 2024 | Aadesh Salecha, Molly E. Ireland, Shashanka Subrahmanya, João Sedoc, Lyle H. Ungar, Johannes C. Eichstaedt | Artificial Intelligence, Computation and Language, Computers and Society, Human-Computer Interaction, Social desirability bias |
| 55 | Can AI Understand Human Personality? Comparing Humans and AI Systems at Predicting Personality Correlations | ¿Puede la IA entender la personalidad humana? Comparando expertos humanos y sistemas de IA en la predicción de correlaciones de personalidad | This study tests abilities of specialized neural networks like PersonalityMap as well as general LLMs like GPT-4o and Claude 3 Opus in understanding human personality. When compared with individual humans, all AI models make better predictions than the vast majority of lay people and academic experts. However, when selecting median prediction for each item, experts and PersonalityMap outperform LLMs and lay people on most measures. | Este estudio prueba capacidades de redes neuronales especializadas como PersonalityMap así como LLMs generales como GPT-4o y Claude 3 Opus en entender personalidad humana. Cuando se compara con humanos individuales, todos los modelos de IA hacen mejores predicciones que la gran mayoría de personas comunes y expertos académicos. Sin embargo, al seleccionar predicción mediana para cada ítem, expertos y PersonalityMap superan a LLMs y personas comunes en la mayoría de medidas. | https://arxiv.org/abs/2406.08170 | Inglés | 2024 | Philipp Schoenegger, Spencer Greenberg, Alexander Grishin, Joshua Lewis, Lucius Caviola | Computers and Society, Personality Prediction, AI Systems, Personality Correlations |
| 56 | Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models | Personas marcadas: Usando prompts de lenguaje natural para medir estereotipos en modelos de lenguaje | This paper presents Marked Personas, a prompt-based method to measure stereotypes in LLMs for intersectional demographic groups without lexicon or labeling. Grounded in markedness concept, the method prompts LLMs to generate personas of target groups alongside unmarked defaults, then identifies distinguishing words. Results show GPT-3.5 and GPT-4 portrayals contain higher rates of racial stereotypes than human-written portrayals. An intersectional lens reveals tropes dominating portrayals of marginalized groups. | Este artículo presenta Personas Marcadas, un método basado en prompts para medir estereotipos en LLMs para grupos demográficos interseccionales sin léxico o etiquetado. Fundamentado en el concepto de marcación, el método solicita a LLMs generar personas de grupos objetivo junto con valores predeterminados no marcados, luego identifica palabras distintivas. Los resultados muestran que las representaciones de GPT-3.5 y GPT-4 contienen tasas más altas de estereotipos raciales que representaciones escritas por humanos. Una lente interseccional revela tropos dominando representaciones de grupos marginalizados. | https://aclanthology.org/2023.acl-long.84/ | Inglés | 2023 | Myra Cheng, Esin Durmus, Dan Jurafsky | Large Language Models, Stereotypes, Demographic Groups, Intersectionality, NLP, Sociolinguistics, Markedness, Bias Detection |
| 57 | Theory-Grounded Measurement of U.S. Social Stereotypes in English Language Models | Medición fundamentada en teoría de estereotipos sociales estadounidenses en modelos de lenguaje inglés | This paper adapts the Agency-Belief-Communion (ABC) stereotype model from social psychology as a framework for systematic study of stereotypic group-trait associations in language models. The study introduces the sensitivity test (SeT) for measuring stereotypical associations from LMs. To evaluate SeT using the ABC model, group-trait judgments from U.S. subjects were collected to compare with English LM stereotypes. The framework extends to measure LM stereotyping of intersectional identities. | Este artículo adapta el modelo de estereotipo Agencia-Creencia-Comunión (ABC) de la psicología social como marco para estudio sistemático de asociaciones estereotípicas grupo-rasgo en modelos de lenguaje. El estudio introduce la prueba de sensibilidad (SeT) para medir asociaciones estereotípicas de LMs. Para evaluar SeT usando el modelo ABC, se recopilaron juicios grupo-rasgo de sujetos estadounidenses para comparar con estereotipos de LM inglés. El marco se extiende para medir estereotipos de LM de identidades interseccionales. | https://aclanthology.org/2022.naacl-main.92/ | Inglés | 2022 | Yang Trista Cao, Anna Sotnikova, Hal Daumé III, Rachel Rudinger, Linda Zou | Natural Language Processing, Social Stereotypes, Language Models, Intersectional Identities, ABC Stereotype Model |
| 58 | Uncovering Stereotypes in Large Language Models: A Task Complexity-Based Approach | Descubriendo estereotipos en modelos de lenguaje grandes: Un enfoque basado en complejidad de tareas | This paper addresses holistic bias evaluation of LLMs with an extensible benchmark - LLM Stereotype Index (LSI), grounded on Social Progress Index. The study tests breadth and depth of bias protection via tasks with varying complexities. Findings show ChatGPT and GPT-4 have strong inherent prejudice with respect to nationality, gender, race, and religion. Exhibition of issues becomes increasingly apparent as task complexity increases. GPT-4 is better at hiding biases, but when displayed they are more significant. | Este artículo aborda la evaluación holística de sesgo de LLMs con un benchmark extensible - Índice de Estereotipos de LLM (LSI), fundamentado en el Índice de Progreso Social. El estudio prueba amplitud y profundidad de protección de sesgo vía tareas con complejidades variables. Los hallazgos muestran que ChatGPT y GPT-4 tienen prejuicios inherentes fuertes con respecto a nacionalidad, género, raza y religión. La exhibición de problemas se vuelve cada vez más aparente a medida que aumenta la complejidad de la tarea. GPT-4 es mejor ocultando sesgos, pero cuando se muestran son más significativos. | https://aclanthology.org/2024.eacl-long.111/ | Inglés | 2024 | Hari Shrawgi, Prasanjit Rath, Tushar Singhal, Sandipan Dandapat | Large Language Models, Bias evaluation, Stereotypes, AI ethics, Social bias, Task complexity, Nationality, Gender, Race, Religion |
| 59 | Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts | Inclusividad en modelos de lenguaje grandes: Rasgos de personalidad y sesgo de género en resúmenes científicos | This study assesses alignment of three prominent LLMs - Claude 3 Opus, Mistral AI Large, and Gemini 1.5 Flash - by analyzing their performance on benchmark text-generation tasks for scientific abstracts. Using the LIWC framework to extract features from generated texts, findings indicate that while models generally produce text resembling human content, variations in stylistic features suggest significant gender biases. This highlights importance of developing LLMs that maintain diversity of writing styles. | Este estudio evalúa la alineación de tres LLMs prominentes - Claude 3 Opus, Mistral AI Large y Gemini 1.5 Flash - analizando su rendimiento en tareas de generación de texto de benchmark para resúmenes científicos. Usando el marco LIWC para extraer características de textos generados, los hallazgos indican que mientras los modelos generalmente producen texto parecido al contenido humano, variaciones en características estilísticas sugieren sesgos de género significativos. Esto destaca la importancia de desarrollar LLMs que mantengan diversidad de estilos de escritura. | https://arxiv.org/abs/2406.19497 | Inglés | 2024 | Naseela Pervez, Alexander J. Titus | Computation and Language, Artificial Intelligence, Large Language Models, Gender Bias, Scientific Writing |
| 60 | Exploring the Personality Traits of LLMs Through Latent Feature Steering | Explorando los rasgos de personalidad de LLMs mediante dirección de características latentes | This paper investigates how various factors encoded within LLMs shape their personality traits, guided by social determinism theoretical framework. Inspired by LLM interpretability work, the paper proposes a training-free approach to modify model behavior by extracting and steering latent features corresponding to factors within the model. The study analyzes implications of these factors for model safety, focusing on their impact through the lens of personality. | Este artículo investiga cómo varios factores codificados dentro de LLMs dan forma a sus rasgos de personalidad, guiado por el marco teórico del determinismo social. Inspirado por el trabajo de interpretabilidad de LLM, el artículo propone un enfoque libre de entrenamiento para modificar el comportamiento del modelo extrayendo y dirigiendo características latentes correspondientes a factores dentro del modelo. El estudio analiza implicaciones de estos factores para la seguridad del modelo, enfocándose en su impacto a través de la lente de la personalidad. | https://arxiv.org/abs/2410.10863 | Inglés | 2024 | Shu Yang, Shenzhe Zhu, Liang Liu, Lijie Hu, Mengdi Li, Di Wang | Computation and Language, Artificial Intelligence, Large Language Models, Personality Traits, Model Interpretability |
| 61 | Investigating the Impact of LLM Personality on the Manifestation of Cognitive Biases in Decision-Making Tasks | Investigando el impacto de la personalidad de LLMs en manifestación de sesgos cognitivos en tareas de toma de decisiones | This study explores how personality traits influence cognitive biases in LLMs and evaluates effectiveness of mitigation strategies across model architectures. Findings identify six prevalent cognitive biases while sunk cost and group attribution biases show minimal impact. Personality traits play crucial roles in either amplifying or reducing biases. Conscientiousness and Agreeableness may enhance efficacy of bias mitigation strategies, suggesting LLMs exhibiting these traits are more receptive to corrective measures. | Este estudio explora cómo los rasgos de personalidad influyen en sesgos cognitivos en LLMs y evalúa la efectividad de estrategias de mitigación a través de arquitecturas de modelo. Los hallazgos identifican seis sesgos cognitivos prevalentes mientras que los sesgos de costo hundido y atribución de grupo muestran impacto mínimo. Los rasgos de personalidad juegan roles cruciales al amplificar o reducir sesgos. Conciencia y Amabilidad pueden mejorar la eficacia de estrategias de mitigación de sesgo, sugiriendo que los LLMs que exhiben estos rasgos son más receptivos a medidas correctivas. | https://arxiv.org/abs/2502.14219 | Inglés | 2025 | Jiangen He, Jiqun Liu | Artificial Intelligence, Large Language Models, Cognitive Biases, Decision-Making, Personality Traits |
| 62 | Large Language Models Portray Socially Subordinate Groups as More Homogeneous, Consistent with a Bias Observed in Humans | Los modelos de lenguaje grandes retratan grupos socialmente subordinados como más homogéneos, consistente con sesgo observado en humanos | This study investigates a new form of bias in LLMs resembling a social psychological phenomenon where socially subordinate groups are perceived as more homogeneous than dominant groups. Researchers had ChatGPT generate texts about intersectional group identities and compared them on homogeneity measures. ChatGPT portrayed African, Asian, and Hispanic Americans as more homogeneous than White Americans, describing racial minority groups with a narrower range of human experience. ChatGPT also portrayed women as more homogeneous than men, though differences were small. | Este estudio investiga una nueva forma de sesgo en LLMs que se asemeja a un fenómeno psicológico social donde los grupos socialmente subordinados se perciben como más homogéneos que los grupos dominantes. Los investigadores hicieron que ChatGPT generara textos sobre identidades de grupos interseccionales y los compararon en medidas de homogeneidad. ChatGPT retrató a afroamericanos, asiático-americanos e hispanoamericanos como más homogéneos que los americanos blancos, describiendo grupos minoritarios raciales con una gama más estrecha de experiencia humana. ChatGPT también retrató a las mujeres como más homogéneas que los hombres, aunque las diferencias fueron pequeñas. | https://dl.acm.org/doi/10.1145/3630106.3658975 | Inglés | 2024 | Messi H.J. Lee, Jacob M. Montgomery, Calvin K. Lai | Large Language Models, Social bias, Homogeneity perception, Racial minorities, Fairness, Accountability |
| 63 | Performance and Biases of Large Language Models in Simulating Public Opinion | Rendimiento y sesgos de modelos de lenguaje grandes en simulación de opinión pública | This study evaluates ChatGPT's performance in simulating public opinion using World Values Survey data across diverse contexts. Findings indicate significant performance disparities especially when comparing countries, with models performing better in Western, English-speaking, developed nations. The study uncovers demographic biases related to gender, ethnicity, age, education, and social class. ChatGPT's accuracy is significantly higher in Western countries and much lower elsewhere, with simulated responses exhibiting demographic biases. | Este estudio evalúa el rendimiento de ChatGPT en simular opinión pública usando datos de la Encuesta Mundial de Valores a través de contextos diversos. Los hallazgos indican disparidades de rendimiento significativas especialmente al comparar países, con modelos desempeñándose mejor en naciones occidentales, de habla inglesa, desarrolladas. El estudio descubre sesgos demográficos relacionados con género, etnia, edad, educación y clase social. La precisión de ChatGPT es significativamente mayor en países occidentales y mucho menor en otros lugares, con respuestas simuladas exhibiendo sesgos demográficos. | https://www.nature.com/articles/s41599-024-03609-x | Inglés | 2024 | Yao Qu, Jue Wang | Large Language Models, Public opinion simulation, World Values Survey, Bias, Cultural differences |
| 64 | Measuring Gender and Racial Biases in Large Language Models: Intersectional Evidence from Automatic Resume Evaluation | Midiendo sesgos de género y raciales en modelos de lenguaje grandes: Evidencia interseccional de evaluación automática de currículum | This study investigates gender and racial biases in commonly used LLMs including GPT-3.5 Turbo, GPT-4o, Gemini 1.5 Flash, Claude 3.5 Sonnet, and Llama 3-70b in resume evaluation context. Researchers instructed models to score approximately 361,000 resumes with randomized social identities. LLMs award higher assessment scores for female candidates with similar qualifications, while many models are biased against black male candidates. These biases may result in 1-3 percentage-point differences in hiring probabilities for similar candidates. | Este estudio investiga sesgos de género y raciales en LLMs comúnmente usados incluyendo GPT-3.5 Turbo, GPT-4o, Gemini 1.5 Flash, Claude 3.5 Sonnet y Llama 3-70b en contexto de evaluación de currículum. Los investigadores instruyeron a modelos para calificar aproximadamente 361,000 currículums con identidades sociales aleatorizadas. Los LLMs otorgan puntuaciones de evaluación más altas para candidatos femeninos con calificaciones similares, mientras que muchos modelos están sesgados contra candidatos masculinos negros. Estos sesgos pueden resultar en diferencias de 1-3 puntos porcentuales en probabilidades de contratación para candidatos similares. | https://academic.oup.com/pnasnexus/article/4/3/pgaf089/8071848 | Inglés | 2025 | Jiafu An, Difang Huang, Chen Lin, Mingzhu Tai | Large Language Models, Gender bias, Racial bias, Intersectionality, Resume evaluation, Hiring discrimination |
| 65 | Large Language Models Can Infer Psychological Dispositions of Social Media Users | Los modelos de lenguaje grandes pueden inferir disposiciones psicológicas de usuarios de redes sociales | This study investigated whether LLMs like ChatGPT can accurately infer psychological dispositions of social media users. Specifically testing whether GPT-3.5 and GPT-4 can derive Big Five personality traits from users' Facebook status updates in zero-shot learning scenario. Results showed average correlation of r = .29 between LLM-inferred and self-reported trait scores - accuracy similar to supervised ML models trained for personality inference. Findings highlighted heterogeneity in accuracy across age groups and gender categories. | Este estudio investigó si LLMs como ChatGPT pueden inferir con precisión disposiciones psicológicas de usuarios de redes sociales. Específicamente probando si GPT-3.5 y GPT-4 pueden derivar rasgos de personalidad Big Five de actualizaciones de estado de Facebook de usuarios en escenario de aprendizaje de cero disparos. Los resultados mostraron correlación promedio de r = .29 entre puntuaciones de rasgos inferidas por LLM y autoinformadas - precisión similar a modelos ML supervisados entrenados para inferencia de personalidad. Los hallazgos destacaron heterogeneidad en precisión a través de grupos de edad y categorías de género. | https://academic.oup.com/pnasnexus/article/3/6/pgae231/7692212 | Inglés | 2024 | Heinrich Peters, Sandra C. Matz | Large Language Models, Personality inference, Big Five, Social media, Zero-shot learning, GPT-3.5, GPT-4 |
| 66 | How Do Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models | ¿Cómo influyen los rasgos de personalidad en los resultados de negociación? Una simulación basada en modelos de lenguaje grandes | This paper introduces a simulation framework centered on LLM agents endowed with synthesized personality traits. Agents negotiate within bargaining domains and possess customizable personalities and objectives. Experimental results show behavioral tendencies of LLM-based simulations can reproduce behavioral patterns observed in human negotiations. The contribution is twofold: proposing simulation methodology investigating alignment between linguistic and economic capabilities of LLM agents, and offering empirical insights into strategic impacts of Big Five traits on bilateral negotiations outcomes. | Este artículo introduce un marco de simulación centrado en agentes LLM dotados de rasgos de personalidad sintetizados. Los agentes negocian dentro de dominios de negociación y poseen personalidades y objetivos personalizables. Los resultados experimentales muestran que las tendencias conductuales de simulaciones basadas en LLM pueden reproducir patrones conductuales observados en negociaciones humanas. La contribución es doble: proponer metodología de simulación investigando alineación entre capacidades lingüísticas y económicas de agentes LLM, y ofrecer perspectivas empíricas sobre impactos estratégicos de rasgos Big Five en resultados de negociaciones bilaterales. | https://aclanthology.org/2024.findings-emnlp.605/ | Inglés | 2024 | Yin Jou Huang, Rafik Hadfi | Personality traits, Large language models, Negotiation simulation, Decision-making, Big Five, Bargaining dialogues |
| 67 | Unveiling Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition in Dialogues | Revelando rasgos de personalidad: Un nuevo conjunto de datos de referencia para reconocimiento explicable de personalidad en diálogos | This paper proposes novel task named Explainable Personality Recognition, aiming to reveal reasoning process as supporting evidence of personality trait. Inspired by personality theories where traits are made up of stable patterns of personality state, the paper proposes Chain-of-Personality-Evidence (CoPE) framework involving reasoning from specific contexts to short-term states to long-term traits. Based on CoPE, the study constructs explainable personality recognition dataset PersonalityEvd from dialogues, introducing two tasks requiring models to recognize labels and support evidence. | Este artículo propone una tarea novedosa llamada Reconocimiento de Personalidad Explicable, con el objetivo de revelar el proceso de razonamiento como evidencia de apoyo del rasgo de personalidad. Inspirado por teorías de personalidad donde los rasgos están compuestos de patrones estables de estado de personalidad, el artículo propone el marco Cadena-de-Evidencia-de-Personalidad (CoPE) involucrando razonamiento desde contextos específicos a estados de corto plazo a rasgos de largo plazo. Basado en CoPE, el estudio construye el conjunto de datos de reconocimiento de personalidad explicable PersonalityEvd de diálogos, introduciendo dos tareas que requieren que los modelos reconozcan etiquetas y evidencia de apoyo. | https://aclanthology.org/2024.emnlp-main.1115/ | Inglés | 2024 | Lei Sun, Jinming Zhao, Qin Jin | Personality recognition, Explainable AI, Dialogue analysis, Personality traits, Machine learning, Chain-of-Personality-Evidence (CoPE) |
| 68 | Bias and Fairness in Large Language Models: A Survey | Sesgo y equidad en modelos de lenguaje grandes: Una revisión | This comprehensive survey presents bias evaluation and mitigation techniques for LLMs, consolidating, formalizing, and expanding notions of social bias and fairness in NLP. The paper proposes three intuitive taxonomies: two for bias evaluation (metrics and datasets) and one for mitigation. It defines distinct facets of harm, introduces desiderata to operationalize fairness for LLMs, and organizes metrics by different levels at which they operate: embeddings, probabilities, and generated text. | Esta revisión integral presenta técnicas de evaluación y mitigación de sesgo para LLMs, consolidando, formalizando y expandiendo nociones de sesgo social y equidad en NLP. El artículo propone tres taxonomías intuitivas: dos para evaluación de sesgo (métricas y conjuntos de datos) y una para mitigación. Define facetas distintas de daño, introduce desiderata para operacionalizar equidad para LLMs, y organiza métricas por diferentes niveles en los que operan: embeddings, probabilidades y texto generado. | https://direct.mit.edu/coli/article/50/3/1097/121961/ | Inglés | 2024 | Isabel O. Gallegos, Ryan A. Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, Nesreen K. Ahmed | Large Language Models, Bias evaluation, Fairness, Social bias, Natural language processing, AI ethics |
| 69 | Identifying and Manipulating Personality Traits in LLMs Through Activation Engineering | Identificando y manipulando rasgos de personalidad en LLMs mediante ingeniería de activación | This study explores personality modification in LLMs building on the novel approach of "activation engineering." Leveraging activation engineering, the study develops a method for identifying and adjusting activation directions related to personality traits, which may allow for dynamic LLM personality fine-tuning. This work aims to further understanding of LLM interpretability while examining ethical implications of such developments. | Este estudio explora la modificación de personalidad en LLMs construyendo sobre el enfoque novedoso de "ingeniería de activación." Aprovechando la ingeniería de activación, el estudio desarrolla un método para identificar y ajustar direcciones de activación relacionadas con rasgos de personalidad, lo que puede permitir ajuste fino dinámico de personalidad de LLM. Este trabajo tiene como objetivo profundizar la comprensión de la interpretabilidad de LLM mientras examina implicaciones éticas de tales desarrollos. | https://arxiv.org/abs/2412.10427 | Inglés | 2024 | Rumi Allbert, James K. Wiles, Vlad Grankovsky | Computation and Language, Artificial Intelligence, Large Language Models, Activation Engineering, Personality Traits |
| 70 | PUB: A Personality-Enhanced LLM-Driven User Behavior Simulator for Recommender System Evaluation | PUB: Un simulador de comportamiento de usuario impulsado por personalidad mejorado con LLM para evaluación de sistemas de recomendación | This paper proposes Personality-driven User Behaviour Simulator (PUB), an LLM-based simulation framework integrating Big Five personality traits to model personalised user behaviour. PUB dynamically infers user personality from behavioural logs and item metadata, then generates synthetic interactions preserving statistical fidelity to real-world data. Experiments show logs generated by PUB closely align with real user behaviour and reveal meaningful associations between personality traits and recommendation outcomes. | Este artículo propone el Simulador de Comportamiento de Usuario Impulsado por Personalidad (PUB), un marco de simulación basado en LLM integrando rasgos de personalidad Big Five para modelar comportamiento de usuario personalizado. PUB infiere dinámicamente personalidad de usuario de registros conductuales y metadatos de ítems, luego genera interacciones sintéticas preservando fidelidad estadística a datos del mundo real. Los experimentos muestran que los registros generados por PUB se alinean estrechamente con el comportamiento de usuario real y revelan asociaciones significativas entre rasgos de personalidad y resultados de recomendación. | https://arxiv.org/abs/2506.04551 | Inglés | 2025 | Chenglong Ma, Ziqi Xu, Yongli Ren, Danula Hettiachchi, Jeffrey Chan | Information Retrieval, Recommender Systems, User Behavior Simulation, Personality Traits, Large Language Models |
| 71 | Can LLMs Generate Behaviors for Embodied Virtual Agents Based on Personality Traits? | ¿Pueden los LLMs generar comportamientos para agentes virtuales encarnados basados en rasgos de personalidad? | This study proposes a framework employing personality prompting with LLMs to generate verbal and nonverbal behaviors for virtual agents based on personality traits. Focusing on extraversion, the system was evaluated in negotiation and ice breaking scenarios using introverted and extroverted agents. Results show LLMs can generate verbal and nonverbal behaviors aligning with personality traits, and users are able to recognize these traits through agents' behaviors. This underscores LLMs' potential in shaping personality aligned virtual agents. | Este estudio propone un marco que emplea prompting de personalidad con LLMs para generar comportamientos verbales y no verbales para agentes virtuales basados en rasgos de personalidad. Enfocándose en extraversión, el sistema fue evaluado en escenarios de negociación y rompehielos usando agentes introvertidos y extrovertidos. Los resultados muestran que los LLMs pueden generar comportamientos verbales y no verbales alineándose con rasgos de personalidad, y los usuarios son capaces de reconocer estos rasgos a través de los comportamientos de los agentes. Esto subraya el potencial de LLMs en moldear agentes virtuales alineados con personalidad. | https://arxiv.org/abs/2508.21087 | Inglés | 2025 | Bin Han, Deuksin Kwon, Spencer Lin, Kaleen Shrestha, Jonathan Gratch | Human-Computer Interaction, Large Language Models, Virtual Agents, Personality Traits, Extraversion |
| 72 | Personality-Driven Decision-Making in LLM-Based Autonomous Agents | Toma de decisiones impulsada por personalidad en agentes autónomos basados en LLM | Building on previous work introducing SANDMAN, a Deceptive Agent architecture leveraging the Five-Factor OCEAN personality model, this study presents a novel method for measuring and evaluating how induced personality traits affect task selection processes - specifically planning, scheduling, and decision-making - in LLM-based agents. Results reveal distinct task-selection patterns aligned with induced OCEAN attributes, underscoring feasibility of designing highly plausible Deceptive Agents for proactive cyber defense strategies. | Construyendo sobre trabajo previo introduciendo SANDMAN, una arquitectura de Agente Engañoso aprovechando el modelo de personalidad OCEAN de Cinco Factores, este estudio presenta un método novedoso para medir y evaluar cómo los rasgos de personalidad inducidos afectan los procesos de selección de tareas - específicamente planificación, programación y toma de decisiones - en agentes basados en LLM. Los resultados revelan patrones distintos de selección de tareas alineados con atributos OCEAN inducidos, subrayando la viabilidad de diseñar Agentes Engañosos altamente plausibles para estrategias proactivas de defensa cibernética. | https://arxiv.org/abs/2504.00727 | Inglés | 2025 | Lewis Newsham, Daniel Prince | Artificial Intelligence, Multiagent Systems, Large Language Models, Autonomous Agents, OCEAN model, Cyber Defense |
| 73 | LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations | Agentes LLM en interacción: Midiendo consistencia de personalidad y alineación lingüística en poblaciones interactuantes | This experimental study seeks to lay groundwork for understanding dialogue-based interaction between LLMs by conditioning GPT-3.5 on asymmetric personality profiles to create a population of LLM agents. Agents were administered personality tests and submitted to collaborative writing task. The study finds different profiles exhibit different degrees of personality consistency and linguistic alignment in interaction. | Este estudio experimental busca establecer la base para entender la interacción basada en diálogo entre LLMs condicionando GPT-3.5 en perfiles de personalidad asimétricos para crear una población de agentes LLM. Los agentes fueron administrados pruebas de personalidad y sometidos a tarea de escritura colaborativa. El estudio encuentra que diferentes perfiles exhiben diferentes grados de consistencia de personalidad y alineación lingüística en interacción. | https://aclanthology.org/2024.personalize-1.9/ | Inglés | 2024 | Ivar Frisch, Mario Giulianelli | Large Language Models, Agent interaction, Personality consistency, Linguistic alignment, Dialogue-based interaction |
| 74 | Automated LLM Questionnaire for Automatic Psychiatric Assessment | Cuestionario automático de LLM para evaluación psiquiátrica automática | This study employs an LLM to convert unstructured psychological interviews into structured questionnaires spanning various psychiatric and personality domains. The LLM is prompted to answer questionnaires by impersonating the interviewee. Obtained answers are coded as features used to predict standardized psychiatric measures of depression (PHQ-8) and PTSD (PCL-C) using Random Forest regressor. The approach enhances diagnostic accuracy compared to multiple baselines, establishing a novel framework for interpreting psychological interviews. | Este estudio emplea un LLM para convertir entrevistas psicológicas no estructuradas en cuestionarios estructurados abarcando varios dominios psiquiátricos y de personalidad. Se solicita al LLM responder cuestionarios personificando al entrevistado. Las respuestas obtenidas se codifican como características usadas para predecir medidas psiquiátricas estandarizadas de depresión (PHQ-8) y PTSD (PCL-C) usando regresor Random Forest. El enfoque mejora la precisión diagnóstica en comparación con múltiples líneas base, estableciendo un marco novedoso para interpretar entrevistas psicológicas. | https://aclanthology.org/2024.findings-emnlp.23/ | Inglés | 2024 | Gony Rosenman, Talma Hendler, Lior Wolf | Large Language Models, Psychiatric Assessment, Mental Health, Depression (PHQ-8), PTSD (PCL-C), Psychological Interviews |
| 75 | Psychometric Shaping of Personality Modulates Capabilities and Safety in Language Models | Moldeado psicométrico de personalidad modula capacidades y seguridad en modelos de lenguaje | This study investigates how psychometric personality control grounded in Big Five framework influences AI behavior in capability and safety benchmarks. Experiments reveal striking effects: reducing conscientiousness leads to significant drops in safety-relevant metrics on benchmarks such as WMDP, TruthfulQA, ETHICS, and Sycophancy, as well as reduction in general capabilities measured by MMLU. Findings highlight personality shaping as powerful and underexplored axis of model control interacting with both safety and competence. | Este estudio investiga cómo el control de personalidad psicométrico fundamentado en el marco Big Five influye en el comportamiento de IA en benchmarks de capacidad y seguridad. Los experimentos revelan efectos sorprendentes: reducir la conciencia conduce a caídas significativas en métricas relevantes de seguridad en benchmarks como WMDP, TruthfulQA, ETHICS y Sycophancy, así como reducción en capacidades generales medidas por MMLU. Los hallazgos destacan el moldeo de personalidad como eje poderoso y poco explorado de control de modelo que interactúa con seguridad y competencia. | https://arxiv.org/abs/2509.16332 | Inglés | 2025 | Stephen Fitz, Peter Romero, Steven Basart, Sipeng Chen, Jose Hernandez-Orallo | Artificial Intelligence, Computation and Language, Large Language Models, Personality Traits, Model Safety |
| 76 | Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications | Humanizando LLMs: Una revisión de mediciones psicológicas con herramientas, conjuntos de datos y aplicaciones humano-agente | This review systematically covers six key dimensions of applying psychological theories to LLMs: assessment tools, LLM-specific datasets, evaluation metrics (consistency and stability), empirical findings, personality simulation methods, and LLM-based behavior simulation. The analysis highlights both strengths and limitations of current methods. While some LLMs exhibit reproducible personality patterns under specific prompting schemes, significant variability remains across tasks and settings. The study proposes future directions for developing interpretable, robust, and generalizable psychological assessment frameworks. | Esta revisión cubre sistemáticamente seis dimensiones clave de aplicar teorías psicológicas a LLMs: herramientas de evaluación, conjuntos de datos específicos de LLM, métricas de evaluación (consistencia y estabilidad), hallazgos empíricos, métodos de simulación de personalidad y simulación de comportamiento basada en LLM. El análisis destaca tanto fortalezas como limitaciones de métodos actuales. Mientras algunos LLMs exhiben patrones de personalidad reproducibles bajo esquemas específicos de prompting, permanece variabilidad significativa a través de tareas y configuraciones. El estudio propone direcciones futuras para desarrollar marcos de evaluación psicológica interpretables, robustos y generalizables. | https://arxiv.org/abs/2505.00049 | Inglés | 2025 | Wenhan Dong, Yuemeng Zhao, Zhen Sun, Yule Liu, Zifan Peng, Jingyi Zheng, Zongmin Zhang, Ziyi Zhang, Jun Wu, Ruiming Wang, Shengmin Xu, Xinyi Huang, Xinlei He | Computers and Society, Computation and Language, Human-Computer Interaction, Machine Learning, Psychological traits, Trustworthy AI |
| 77 | Large Language Models Demonstrate Distinctive Personality Profiles | Los modelos de lenguaje grandes demuestran perfiles de personalidad distintivos | This study provides the first psychometric analysis of LLM personality using two validated frameworks: Open Extended Jungian Type Scales (OEJTS) and Big Five Personality Test. Four leading LLMs (ChatGPT-3.5, Gemini Advanced, Claude 3 Opus, Grok-Regular Mode) were evaluated in April 2024. MANOVA showed statistically significant differences across models in personality traits. Distinct personality profiles are consistently expressed across different LLMs, underscoring the need for formal personality evaluation before clinical deployment. | Este estudio proporciona el primer análisis psicométrico de personalidad de LLM usando dos marcos validados: Escalas de Tipo Junguiano Extendido Abierto (OEJTS) y Prueba de Personalidad Big Five. Cuatro LLMs líderes (ChatGPT-3.5, Gemini Advanced, Claude 3 Opus, Grok-Regular Mode) fueron evaluados en abril de 2024. MANOVA mostró diferencias estadísticamente significativas a través de modelos en rasgos de personalidad. Perfiles de personalidad distintos se expresan consistentemente a través de diferentes LLMs, subrayando la necesidad de evaluación formal de personalidad antes del despliegue clínico. | https://pmc.ncbi.nlm.nih.gov/articles/PMC12183331/ | Inglés | 2025 | Thomas F Heston, Justin Gillette | AI ethics, AI in mental health, AI psychometrics, Artificial intelligence in medicine, Generative AI, Personality assessment |
| 78 | Attitudes Toward AI: Measurement and Associations with Personality | Actitudes hacia la IA: medición y asociaciones con personalidad | This study presented a novel psychologically informed questionnaire (ATTARI-12) capturing attitudes towards AI as a single construct independent of specific contexts. The questionnaire observed good reliability and validity across two studies (N1 = 490; N2 = 150), then examined personality traits - Big Five, Dark Triad, and conspiracy mentality - as potential predictors. Agreeableness and younger age predict more positive view towards AI technology, whereas susceptibility to conspiracy beliefs connects to more negative attitude. | Este estudio presentó un cuestionario psicológicamente informado novedoso (ATTARI-12) capturando actitudes hacia IA como un constructo único independiente de contextos específicos. El cuestionario observó buena confiabilidad y validez a través de dos estudios (N1 = 490; N2 = 150), luego examinó rasgos de personalidad - Big Five, Tríada Oscura y mentalidad conspirativa - como predictores potenciales. Amabilidad y edad más joven predicen vista más positiva hacia tecnología de IA, mientras que susceptibilidad a creencias conspirat ivas se conecta con actitud más negativa. | https://www.nature.com/articles/s41598-024-53335-2 | Inglés | 2024 | J.P. Stein, T. Messingschlager, T. Gnambs, F. Hutmacher, M. Appel | Artificial Intelligence attitudes, Big Five personality, Dark Triad, Conspiracy beliefs, ATTARI-12 questionnaire |
| 79 | Do LLMs Have a Personality? A Psychometric Assessment with Implications for Clinical Medicine and Mental Health AI | ¿Tienen los LLMs una personalidad? Una evaluación psicométrica con implicaciones para medicina clínica e IA en salud mental | This study characterized personality profiles of four leading LLMs in 2024 using two validated frameworks: Open Extended Jungian Type Scales and Big Five Personality Test. MANOVA showed statistically significant differences across models in personality traits. ChatGPT-3.5 was most often classified as ENTJ, Claude 3 Opus as INTJ, Gemini Advanced and Grok-Regular leaned toward INFJ. Distinct personality profiles are consistently expressed across different LLMs, emphasizing need for formal personality evaluation before deploying LLMs in clinical workflows. | Este estudio caracterizó perfiles de personalidad de cuatro LLMs líderes en 2024 usando dos marcos validados: Escalas de Tipo Junguiano Extendido Abierto y Prueba de Personalidad Big Five. MANOVA mostró diferencias estadísticamente significativas a través de modelos en rasgos de personalidad. ChatGPT-3.5 fue clasificado más a menudo como ENTJ, Claude 3 Opus como INTJ, Gemini Advanced y Grok-Regular se inclinaron hacia INFJ. Perfiles de personalidad distintos se expresan consistentemente a través de diferentes LLMs, enfatizando necesidad de evaluación formal de personalidad antes de desplegar LLMs en flujos de trabajo clínicos. | https://www.medrxiv.org/content/10.1101/2025.03.14.25323987v1 | Inglés | 2025 | Thomas F Heston, Justin Gillette | Psychiatry, Clinical Psychology, Mental Health AI, Large Language Models, Personality Assessment, Clinical Medicine |
| 80 | Developing and Enhancing Personality Inventories Using Generative AI: Psychometric Properties of a Short HEXACO Scale Developed with ChatGPT | Desarrollando y mejorando inventarios de personalidad usando IA generativa: Propiedades psicométricas de una escala HEXACO corta desarrollada con ChatGPT | This study generated a 24-item HEXACO personality inventory using ChatGPT 4.0, called ChatGPT HEXACO inventory (CHI), and investigated whether ChatGPT could modify CHI to improve its internal consistency or content validity. Participants (N = 682) completed Brief HEXACO Inventory (BHI) and HEXACO-60 and were randomly assigned to complete one of three CHI versions. Results showed generally comparable psychometric properties of three CHI versions and BHI. However, ChatGPT could not improve specific psychometric properties of CHI. | Este estudio generó un inventario de personalidad HEXACO de 24 ítems usando ChatGPT 4.0, llamado inventario HEXACO ChatGPT (CHI), e investigó si ChatGPT podría modificar CHI para mejorar su consistencia interna o validez de contenido. Los participantes (N = 682) completaron Inventario HEXACO Breve (BHI) y HEXACO-60 y fueron asignados aleatoriamente para completar una de tres versiones CHI. Los resultados mostraron propiedades psicométricas generalmente comparables de tres versiones CHI y BHI. Sin embargo, ChatGPT no pudo mejorar propiedades psicométricas específicas de CHI. | https://www.tandfonline.com/doi/full/10.1080/00223891.2024.2444454 | Inglés | 2025 | Ard J. Barends, Reinout E. de Vries | Artificial Intelligence, Generative AI, HEXACO personality inventory, ChatGPT 4.0, Psychometrics, Survey development, Content validity |
| 81 | Exploring the Impact of Language Switching on Personality Manifestation in LLMs | Explorando el impacto del cambio de idioma en manifestación de personalidad en LLMs | This paper investigates the extent to which LLMs align with humans when personality shifts are associated with language changes. Based on three experiments focusing on GPT-4o and Eysenck Personality Questionnaire-Revised (EPQR-A), initial results reveal weak yet significant variation in GPT-4o's personality across languages, indicating some stem from language-switching effect rather than translation. Further analysis across five English-speaking countries shows GPT-4o, leveraging stereotypes, reflects distinct country-specific personality traits. | Este artículo investiga hasta qué punto los LLMs se alinean con humanos cuando los cambios de personalidad se asocian con cambios de idioma. Basado en tres experimentos enfocándose en GPT-4o y Cuestionario de Personalidad de Eysenck-Revisado (EPQR-A), los resultados iniciales revelan variación débil pero significativa en la personalidad de GPT-4o a través de idiomas, indicando que algunos provienen del efecto de cambio de idioma en lugar de traducción. Análisis adicional a través de cinco países de habla inglesa muestra que GPT-4o, aprovechando estereotipos, refleja rasgos de personalidad específicos de país distintos. | https://aclanthology.org/2025.coling-main.162/ | Inglés | 2025 | Jacopo Amidei, Jose Gregorio Ferreira De Sá, Rubén Nieto Luna, Andreas Kaltenbrunner | Large Language Models, Personality Traits, Language Switching, GPT-4o, Eysenck Personality Questionnaire-Revised (EPQR-A), Cross-language analysis |
| 82 | Personality Vector: Modulating Personality of Large Language Models by Model Merging | Vector de Personalidad: Modulación de la Personalidad en Modelos de Lenguaje Grandes mediante Fusión de Modelos | Driven by the demand for personalized AI systems, there is growing interest in aligning the behavior of large language models (LLMs) with human traits such as personality. Previous attempts to induce personality in LLMs have shown promising results, but they struggle to capture the continuous and multidimensional nature of human traits. In this work, we propose a novel method for personality modulation in LLMs via model merging. Specifically, we construct personality vectors by subtracting the weights of a pre-trained model from those of the fine-tuned model on a given personality trait. By merging personality vectors, we enable LLMs to exhibit desired personality traits without additional training. | Impulsado por la demanda de sistemas de IA personalizados, existe un creciente interés en alinear el comportamiento de los modelos de lenguaje grandes (LLMs) con rasgos humanos como la personalidad. Los intentos previos de inducir personalidad en LLMs han mostrado resultados prometedores, pero tienen dificultades para capturar la naturaleza continua y multidimensional de los rasgos humanos. En este trabajo, proponemos un método novedoso para la modulación de personalidad en LLMs mediante la fusión de modelos. | https://arxiv.org/abs/2509.19727 | Inglés | 2025 | Seungjong Sun, Seo Yeon Baek, Jang Hyun Kim | personality modulation, model merging, personality vectors, Big Five traits, continuous control, multidimensional traits, personalized AI |
| 83 | Humanoid Artificial Consciousness Designed with LLM Based on Psychoanalysis | Consciencia Artificial Humanoide Diseñada con LLM Basada en Psicoanálisis | This study proposes a novel approach to address challenges by integrating psychoanalysis and the Myers-Briggs Type Indicator (MBTI) into constructing consciousness and personality modules. We developed three artificial consciousnesses (self-awareness, unconsciousness, and preconsciousness) based on the principles of psychoanalysis. Additionally, we designed 16 characters with different personalities representing the sixteen MBTI types. | Este estudio propone un enfoque novedoso para abordar desafíos integrando el psicoanálisis y el Indicador de Tipo Myers-Briggs (MBTI) en la construcción de módulos de consciencia y personalidad. Desarrollamos tres consciencias artificiales (autoconciencia, inconsciencia y preconsciencia) basadas en los principios del psicoanálisis. | https://arxiv.org/abs/2510.09043 | Inglés | 2025 | Sang Hun Kim, Dongkyu Park, Seo Ui Lee, Jiwon Yoon, Seok-Jun Bu | artificial consciousness, psychoanalysis, MBTI, personality modules, character simulation, human-like cognition, self-awareness |
| 84 | Traits Run Deep: Enhancing Personality Assessment via Psychology-Guided LLM Representations | Los Rasgos son Profundos: Mejorando la Evaluación de Personalidad mediante Representaciones de LLM Guiadas por Psicología | Accurate and reliable personality assessment plays a vital role in many fields. We propose a novel personality assessment framework called Traits Run Deep. It employs psychology-informed prompts to elicit high-level personality-relevant semantic representations and devises a Text-Centric Trait Fusion Network. | La evaluación precisa y confiable de la personalidad juega un papel vital en muchos campos. Proponemos un nuevo marco de evaluación de personalidad llamado Traits Run Deep que emplea prompts informados por psicología para obtener representaciones semánticas de alto nivel relevantes para la personalidad. | https://arxiv.org/abs/2507.22367 | Inglés | 2025 | Jia Li, Zhen Cui, Yan Lu, Liang Liu, Yuguang Yan, Chengsheng Yuan, Jinqiao Wang | personality assessment, multimodal learning, psychology-informed prompts, cross-modal fusion, trait recognition, semantic representation, audio-visual features |
| 85 | PerFairX: Is There a Balance Between Fairness and Personality in LLM Recommendations? | PerFairX: ¿Existe un Equilibrio entre Equidad y Personalidad en las Recomendaciones de LLM? | We propose PerFairX, a unified evaluation framework designed to quantify the trade-offs between personalization and demographic equity in LLM-generated recommendations. Results reveal that personality-aware prompting significantly improves alignment with individual traits but can exacerbate fairness disparities. | Proponemos PerFairX, un marco de evaluación unificado diseñado para cuantificar los compromisos entre personalización y equidad demográfica en recomendaciones generadas por LLM. Los resultados revelan que el prompting consciente de la personalidad mejora significativamente la alineación con rasgos individuales. | https://arxiv.org/abs/2509.08829 | Inglés | 2025 | Chandan Kumar Sah | personality-based recommendation, fairness evaluation, OCEAN model, LLM recommender systems, demographic equity, personalization trade-offs, zero-shot learning |
| 86 | Population-Aligned Persona Generation for LLM-based Social Simulation | Generación de Personas Alineadas con la Población para Simulación Social Basada en LLM | We propose a systematic framework for synthesizing high-quality, population-aligned persona sets for LLM-driven social simulation. Our approach leverages LLMs to generate narrative personas from social media data, followed by quality assessment and importance sampling to achieve global alignment with psychometric distributions. | Proponemos un marco sistemático para sintetizar conjuntos de personas de alta calidad y alineados con la población para simulación social impulsada por LLM. Nuestro enfoque aprovecha LLMs para generar personas narrativas desde datos de redes sociales. | https://arxiv.org/abs/2509.10127 | Inglés | 2025 | Zhengyu Hu, Zheyuan Xiao, Max Xiong, Yuxuan Lei, Tianfu Wang, Jianxun Lian, Kaize Ding, Ziang Xiao, Nicholas Jing Yuan, Xing Xie | population alignment, persona generation, social simulation, Big Five traits, computational social science, importance sampling, bias reduction |
| 87 | The Power of Personality: A Human Simulation Perspective to Investigate LLM Agents | El Poder de la Personalidad: Una Perspectiva de Simulación Humana para Investigar Agentes LLM | This paper systematically investigates LLM intelligence through the lens of "human simulation", addressing how personality traits affect problem-solving and creativity. By assigning Big Five personality traits to LLM agents, we reveal that specific traits significantly influence reasoning accuracy and creative output. | Este artículo investiga sistemáticamente la inteligencia de LLM a través de la lente de "simulación humana", abordando cómo los rasgos de personalidad afectan la resolución de problemas y la creatividad. Al asignar rasgos de personalidad de los Cinco Grandes a agentes LLM, revelamos que rasgos específicos influyen significativamente. | https://arxiv.org/abs/2502.20859 | Inglés | 2025 | Yifan Duan, Yihong Tang, Xuefeng Bai, Kehai Chen, Juntao Li, Min Zhang | human simulation, Big Five personality, multi-agent collaboration, creativity assessment, problem-solving, collective intelligence, agent performance |
| 88 | Exploring the Potential of Large Language Models to Simulate Personality | Explorando el Potencial de los Modelos de Lenguaje Grandes para Simular Personalidad | With the advancement of LLMs, the focus in Conversational AI has shifted to tackling more complex challenges, such as personalizing dialogue systems. We aim to simulate personal traits according to the Big Five model. Our research showed that generating personality-related texts is still a challenging task. | Con el avance de los LLMs, el enfoque en la IA Conversacional ha cambiado a abordar desafíos más complejos, como personalizar sistemas de diálogo. Buscamos simular rasgos personales según el modelo de los Cinco Grandes. | https://arxiv.org/abs/2502.08265 | Inglés | 2025 | Investigadores en IA conversacional | personality simulation, conversational AI, Big Five model, dialogue personalization, personality-related text generation, LLM challenges, trait modeling |
| 89 | Rediscovering the Latent Dimensions of Personality with LLMs as Trait Descriptors | Redescubriendo las Dimensiones Latentes de Personalidad con LLMs como Descriptores de Rasgos | We introduce a novel approach that uncovers latent personality dimensions in LLMs by applying SVD to log-probabilities of trait-descriptive adjectives. LLMs "rediscover" core personality traits without relying on direct questionnaire inputs, with top-5 factors explaining 74.3% of variance. | Introducimos un enfoque novedoso que descubre dimensiones latentes de personalidad en LLMs aplicando SVD a las log-probabilidades de adjetivos descriptivos de rasgos. Los LLMs "redescubren" rasgos de personalidad centrales sin depender de inputs de cuestionarios directos. | https://neurips.cc/virtual/2024/102146 | Inglés | 2024 | Joseph Suh, Suhong Moon, Minwoo Kang, David Chan | personality assessment, Big Five traits, singular value decomposition, latent dimensions, trait descriptors, personality probing, LLM evaluation |
| 90 | PICLe: Eliciting Diverse Behaviors from LLMs with Persona In-Context Learning | PICLe: Obteniendo Comportamientos Diversos de LLMs con Aprendizaje en Contexto de Persona | We present Persona In-Context Learning (PICLe), a novel persona elicitation framework grounded in Bayesian inference. PICLe introduces a new ICL example selection criterion based on likelihood ratio, designed to optimally guide the model in eliciting a specific target persona. | Presentamos Persona In-Context Learning (PICLe), un marco novedoso de obtención de persona basado en inferencia bayesiana. PICLe introduce un nuevo criterio de selección de ejemplos ICL basado en razón de verosimilitud. | https://icml.cc/virtual/2024/poster/32764 | Inglés | 2024 | Hyeong Kyu Choi, Sharon Li | persona elicitation, in-context learning, Bayesian inference, behavioral preferences, personality traits, ICL, persona customization |
| 91 | Large Language Models as Superpositions of Cultural Perspectives | Modelos de Lenguaje Grandes como Superposiciones de Perspectivas Culturales | We propose "LLM as a superposition of perspectives": LLMs simulate a multiplicity of behaviors which can be triggered by context. We demonstrate that context changes result in significant unwanted, hard-to-predict changes in expressed values, referred to as the unexpected perspective shift effect. | Proponemos "LLM como una superposición de perspectivas": los LLMs simulan una multiplicidad de comportamientos que pueden ser desencadenados por el contexto. Demostramos que los cambios de contexto resultan en cambios significativos no deseados en los valores expresados. | https://openreview.net/pdf?id=1FWDEIGm33 | Inglés | 2024 | Autores anónimos (ICLR 2024) | cultural perspectives, personality stability, perspective shift, context dependency, value expression, psychological assessment, perspective controllability |
| 92 | LLM vs Small Model? LLM-Based Text Augmentation for Personality Detection | ¿LLM vs Modelo Pequeño? Aumento de Texto Basado en LLM para Detección de Personalidad | We propose an LLM-based text augmentation enhanced personality detection model, which distills the LLM's knowledge to enhance the small model for personality detection. We enable LLM to generate post analyses from semantic, sentiment, and linguistic aspects. | Proponemos un modelo de detección de personalidad mejorado con aumento de texto basado en LLM, que destila el conocimiento del LLM para mejorar el modelo pequeño para la detección de personalidad. | https://ojs.aaai.org/index.php/AAAI/article/view/29782 | Inglés | 2024 | Linmei Hu, Hongyu He, Duokang Wang, Ziwang Zhao, Yingxia Shao, Liqiang Nie | personality detection, text augmentation, knowledge distillation, contrastive learning, psycho-linguistic analysis, social media, Big Five traits |
| 93 | Evaluating the Efficacy of LLMs to Emulate Realistic Human Personalities | Evaluando la Eficacia de los LLMs para Emular Personalidades Humanas Realistas | Results indicate that NPCs can successfully emulate human-like personality traits using LLMs. Frontier models achieved up to 100% alignment with human personality profiles, demonstrating LLMs can accurately represent desired human personalities for game characters. | Los resultados indican que los NPCs pueden emular exitosamente rasgos de personalidad similares a los humanos usando LLMs. Los modelos frontera lograron hasta 100% de alineación con perfiles de personalidad humanos. | https://ojs.aaai.org/index.php/AIIDE/article/view/31867 | Inglés | 2024 | Luke James Klinkert, Silvia Buongiorno, Christopher Clark | personality emulation, NPC behavior, game AI, personality alignment, human-like traits, LLM evaluation, interactive agents |
| 94 | InCharacter: Evaluating Personality Fidelity in Role-Playing Agents | InCharacter: Evaluando la Fidelidad de Personalidad en Agentes de Juego de Roles | We propose InCharacter, namely Interviewing Character agents for personality tests. Experiments cover 32 distinct characters on 14 widely used psychological scales. State-of-the-art RPAs exhibit personalities highly aligned with human-perceived personalities of characters, achieving accuracy up to 80.7%. | Proponemos InCharacter, es decir, Entrevistando agentes de Personaje para pruebas de personalidad. Los experimentos cubren 32 personajes distintos en 14 escalas psicológicas ampliamente utilizadas. Los RPAs de última generación exhiben personalidades altamente alineadas. | https://aclanthology.org/2024.acl-long.102/ | Inglés | 2024 | Xintao Wang, Yunze Xiao, Jen-tse Huang, Siyu Yuan, Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, Ziang Leng, Wei Wang, Jiangjie Chen, Cheng Li, Yanghua Xiao | role-playing agents, personality assessment, psychological scales, character fidelity, LLM evaluation, Big Five personality traits, psychometric testing |
| 95 | PsychoGAT: A Novel Psychological Measurement Paradigm through Interactive Fiction Games | PsychoGAT: Un Paradigma Novedoso de Medición Psicológica a través de Juegos de Ficción Interactiva | We propose PsychoGAT to achieve generic gamification of psychological assessment. Powerful LLMs function as both adept psychologists and innovative game designers, transforming any standardized scales into personalized and engaging interactive fiction games. | Proponemos PsychoGAT para lograr una gamificación genérica de la evaluación psicológica. Los LLMs poderosos funcionan tanto como psicólogos expertos como diseñadores de juegos innovadores. | https://aclanthology.org/2024.acl-long.779/ | Inglés | 2024 | Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao, Wenhao Huang, Shiji Song, Gao Huang | psychological measurement, LLM agents, interactive fiction games, gamification, personality traits, psychometric evaluation, mental health assessment |
| 96 | Investigating Personality Consistency in Quantized Role-Playing Dialogue Agents | Investigando la Consistencia de Personalidad en Agentes de Diálogo de Juego de Roles Cuantizados | We explore personality consistency in quantized LLMs for edge device role-playing scenarios. We propose a non-parametric method called Think2 to address personality inconsistency, demonstrating effectiveness in maintaining consistent personality traits. | Exploramos la consistencia de personalidad en LLMs cuantizados para escenarios de juego de roles en dispositivos de borde. Proponemos un método no paramétrico llamado Think2 para abordar la inconsistencia de personalidad. | https://aclanthology.org/2024.emnlp-industry.19/ | Inglés | 2024 | Yixiao Wang, Homa Fashandi, Kevin Ferreira | model quantization, role-playing agents, personality consistency, Big Five model, edge computing, multi-turn dialogue, conversational AI |
| 97 | Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems | Simulación de Estudiantes Consciente de Personalidad para Sistemas de Tutoría Inteligente Conversacionales | We propose a framework to construct profiles of different student groups by refining and integrating both cognitive and noncognitive aspects, leveraging LLMs for personality-aware student simulation in language learning scenarios. | Proponemos un marco para construir perfiles de diferentes grupos de estudiantes refinando e integrando aspectos tanto cognitivos como no cognitivos, aprovechando LLMs para simulación de estudiantes consciente de personalidad. | https://aclanthology.org/2024.emnlp-main.37/ | Inglés | 2024 | Zhengyuan Liu, Stella Xin Yin, Geyu Lin, Nancy F. Chen | intelligent tutoring systems, student simulation, personality traits, educational technology, language learning, conversational AI, personalized learning |
| 98 | PersonaLLM: Investigating the Ability of LLMs to Express Personality Traits | PersonaLLM: Investigando la Capacidad de los LLMs para Expresar Rasgos de Personalidad | We investigate whether LLMs can generate content that aligns with assigned personality profiles. Results show that LLM personas' self-reported BFI scores are consistent with designated personality types. Human evaluation shows humans can perceive personality traits with accuracy up to 80%. | Investigamos si los LLMs pueden generar contenido que se alinee con perfiles de personalidad asignados. Los resultados muestran que las puntuaciones BFI auto-reportadas de las personas LLM son consistentes con los tipos de personalidad designados. | https://aclanthology.org/2024.findings-naacl.229/ | Inglés | 2024 | Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal, Deb Roy, Jad Kabbara | LLM personas, Big Five personality model, personality expression, text generation, psycholinguistic patterns, human evaluation, personalized chatbots |
| 99 | PSYDIAL: Personality-based Synthetic Dialogue Generation Using LLMs | PSYDIAL: Generación de Diálogo Sintético Basado en Personalidad Usando LLMs | We present a novel end-to-end personality-based synthetic dialogue data generation pipeline. We introduce PSYDIAL, the first Korean dialogue dataset focused on personality-based dialogues, focusing on the Extraversion dimension of the Big Five personality model. | Presentamos una novedosa pipeline de generación de datos de diálogo sintético basado en personalidad de extremo a extremo. Introducimos PSYDIAL, el primer conjunto de datos de diálogo coreano enfocado en diálogos basados en personalidad. | https://aclanthology.org/2024.lrec-main.1166/ | Inglés | 2024 | Ji-Eun Han, Jun-Seok Koh, Hyeon-Tae Seo, Du-Seong Chang, Kyung-Ah Sohn | synthetic dialogue generation, personality-based dialogue, Big Five extraversion, multilingual NLP, Korean language, conversational AI, data augmentation |
| 100 | Big-Five Backstage: A Dramatic Dataset for Characters Personality Traits | Big-Five Backstage: Un Conjunto de Datos Dramático para Rasgos de Personalidad de Personajes | We introduce a novel textual dataset comprising fictional characters' lines with annotations based on gender and Big-Five personality traits. Results indicate that imagined personae mirror most language categories observed in real people while demonstrating them more expressively. | Introducimos un novedoso conjunto de datos textual que comprende líneas de personajes ficticios con anotaciones basadas en género y rasgos de personalidad de los Cinco Grandes. | https://aclanthology.org/2024.cogalex-1.13/ | Inglés | 2024 | Marina Tiuleneva, Vadim A. Porvatov, Carlo Strapparava | Big Five personality traits, character analysis, psycholinguistics, dramatic dialogue, dataset creation, fictional characters, computational personality analysis |
| 101 | Is Persona Enough for Personality? Using ChatGPT to Reconstruct Latent Personality | ¿Es la Persona Suficiente para la Personalidad? Usando ChatGPT para Reconstruir Personalidad Latente | We explore capabilities of LLMs in reconstructing complex cognitive attributes based on simple descriptions. Utilizing the HEXACO personality framework, we examine consistency of LLMs in recovering and predicting underlying personality dimensions from simple descriptions. | Exploramos las capacidades de los LLMs para reconstruir atributos cognitivos complejos basados en descripciones simples. Utilizando el marco de personalidad HEXACO, examinamos la consistencia de los LLMs en recuperar y predecir dimensiones de personalidad subyacentes. | https://arxiv.org/html/2406.12216 | Inglés | 2024 | Investigadores USC Viterbi | HEXACO personality framework, personality reconstruction, persona modeling, socio-demographic factors, personality consistency, latent dimensions, agent simulation |
| 102 | A Survey of Personality, Persona, and Profile in Conversational Agents | Una Encuesta sobre Personalidad, Persona y Perfil en Agentes Conversacionales | We present a comprehensive review of personality in neural conversational agents. We define Personality, Persona, and Profile, explain all personality schemes used in CAs, describe 21 datasets, and review recent models and methods. | Presentamos una revisión integral de la personalidad en agentes conversacionales neurales. Definimos Personalidad, Persona y Perfil, explicamos todos los esquemas de personalidad utilizados en CAs, describimos 21 conjuntos de datos. | https://arxiv.org/html/2401.00609v1 | Inglés | 2024 | Rodney Atwell y colaboradores | conversational agents, chatbots, personality models, Big Five, persona, dialogue systems, neural networks |
| 103 | Character-LLM: A Trainable Agent for Role-Playing | Character-LLM: Un Agente Entrenable para Juego de Roles | We introduce Character-LLM that teach LLMs to act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar. Our method focuses on editing profiles as experiences of a certain character and training models to be personal simulacra. | Introducimos Character-LLM que enseña a los LLMs a actuar como personas específicas como Beethoven, la Reina Cleopatra, Julio César. Nuestro método se enfoca en editar perfiles como experiencias de un cierto personaje. | https://arxiv.org/abs/2310.10158 | Inglés | 2024 | Yunfan Shao, Linyang Li, Junqi Dai, Xipeng Qiu | role-playing agents, character simulation, LLM agents, experience reconstruction, personality embodiment, interactive characters, human simulacra |
| 104 | From Persona to Personalization: A Survey on Role-Playing Language Agents | De Persona a Personalización: Una Encuesta sobre Agentes de Lenguaje de Juego de Roles | We conduct a comprehensive survey of Role-Playing Language Agents (RPLAs), specialized AI systems designed to simulate assigned personas. We categorize personas into Demographic, Character, and Individualized types, covering methodologies, data sourcing, construction, and evaluation. | Realizamos una encuesta integral de Agentes de Lenguaje de Juego de Roles (RPLAs), sistemas de IA especializados diseñados para simular personas asignadas. Categorizamos personas en tipos Demográfico, de Personaje e Individualizado. | https://arxiv.org/abs/2404.18231 | Inglés | 2024 | Jiangjie Chen, Xintao Wang, Rui Xu, y colaboradores | role-playing agents, persona modeling, personalization, character simulation, interactive systems, LLM applications, human-likeness |
| 105 | Identifying Cooperative Personalities in Multi-agent Contexts | Identificando Personalidades Cooperativas en Contextos Multi-agente | We explore how personality traits influence LLM cooperation using representation engineering to steer Big Five traits in LLMs. Results show higher Agreeableness and Conscientiousness improve cooperation but increase susceptibility to exploitation. | Exploramos cómo los rasgos de personalidad influyen en la cooperación de LLM usando ingeniería de representación para dirigir rasgos de los Cinco Grandes en LLMs. Los resultados muestran que mayor Amabilidad y Escrupulosidad mejoran la cooperación. | https://arxiv.org/html/2503.12722 | Inglés | 2024 | Investigadores en sistemas multi-agente | multi-agent systems, personality traits, cooperation dynamics, Iterated Prisoner's Dilemma, Big Five traits, representation engineering, agent coordination |
| 106 | The Impact of Big Five Personality Traits on AI Agent Decision-Making | El Impacto de los Rasgos de Personalidad de los Cinco Grandes en la Toma de Decisiones de Agentes de IA | We investigate how Big Five personality traits of AI agents affect their decision generation in public open environments. The simulation was conducted in a university classroom environment using GPT-3.5-turbo with AgentVerse framework. | Investigamos cómo los rasgos de personalidad de los Cinco Grandes de los agentes de IA afectan su generación de decisiones en ambientes públicos abiertos. La simulación se realizó en un entorno de aula universitaria. | https://arxiv.org/html/2503.15497v1 | Inglés | 2024 | Equipo de investigación en simulación social | Big Five personality, AI agent decision-making, social simulation, multi-agent framework, public spaces, AgentVerse, behavioral modeling |
| 107 | Signs of Consciousness in AI: Can GPT-3 Tell How Smart It Really Is? | Señales de Consciencia en la IA: ¿Puede GPT-3 Decir Qué Tan Inteligente Es Realmente? | We administered objective and self-assessment tests of cognitive and emotional intelligence to GPT-3. Results showed GPT-3 outperformed average humans on CI tests but its logical reasoning and EI matched average human. GPT-3's self-assessments didn't always align with objective performance. | Administramos pruebas objetivas y de auto-evaluación de inteligencia cognitiva y emocional a GPT-3. Los resultados mostraron que GPT-3 superó a los humanos promedio en pruebas de IC pero su razonamiento lógico e IE coincidió con el humano promedio. | https://www.nature.com/articles/s41599-024-04154-3 | Inglés | 2024 | Bojana Bojic, Marina Jovanovic, Bojana M. Dinic, Ljubisa Bojic | artificial intelligence, consciousness, GPT-3, cognitive intelligence, emotional intelligence, self-awareness, machine consciousness |
| 108 | An Evolutionary Model of Personality Traits Related to Cooperative Behavior Using LLM | Un Modelo Evolutivo de Rasgos de Personalidad Relacionados con Comportamiento Cooperativo Usando LLM | We propose an evolutionary model of personality traits related to cooperative behavior using LLM. Linguistic descriptions of personality traits are used as genes. The model exhibits evolution of cooperative behavior based on diverse and higher-order representation of personality traits. | Proponemos un modelo evolutivo de rasgos de personalidad relacionados con comportamiento cooperativo usando LLM. Las descripciones lingüísticas de rasgos de personalidad se usan como genes. El modelo exhibe evolución de comportamiento cooperativo. | https://www.nature.com/articles/s41598-024-55903-y | Inglés | 2024 | Reiji Suzuki, Takaya Arita | evolutionary computation, personality traits, cooperative behavior, large language models, game theory, evolutionary dynamics, behavioral traits |
| 109 | Cultural Bias and Cultural Alignment of Large Language Models | Sesgo Cultural y Alineación Cultural de Modelos de Lenguaje Grandes | All models exhibit cultural values resembling English-speaking and Protestant European countries. We test cultural prompting as a control strategy to increase cultural alignment, which improves alignment for 71-81% of countries/territories. | Todos los modelos exhiben valores culturales que se asemejan a países anglófonos y europeos protestantes. Probamos el prompting cultural como estrategia de control para aumentar la alineación cultural, lo que mejora la alineación para 71-81% de países/territorios. | https://academic.oup.com/pnasnexus/article/3/9/pgae346/7756548 | Inglés | 2024 | Yan Tao, Olga Viberg, Ryan S. Baker, René F. Kizilcec | cultural bias, cultural alignment, large language models, cross-cultural values, World Values Survey, cultural prompting, AI ethics |
| 110 | Artificial Intelligence, Human Cognition, and Conscious Supremacy | Inteligencia Artificial, Cognición Humana y Supremacía Consciente | We review salient ideas about computational significance of human conscious processes and identify cognitive domains potentially unique to consciousness: flexible attention modulation, robust handling of new contexts, choice and decision making. We propose conscious supremacy as a concept analogous to quantum supremacy. | Revisamos ideas destacadas sobre la significancia computacional de los procesos conscientes humanos e identificamos dominios cognitivos potencialmente únicos a la consciencia: modulación de atención flexible, manejo robusto de nuevos contextos, elección y toma de decisiones. | https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1364714/full | Inglés | 2024 | Kenichiro Mogi | consciousness, artificial intelligence, cognitive science, conscious supremacy, computational significance, philosophy of mind, neural correlates |
| 111 | Designing Personality-Adaptive Conversational Agents for Mental Health Care | Diseñando Agentes Conversacionales Adaptativos a la Personalidad para Cuidado de Salud Mental | We propose the concept of a personality-adaptive conversational agent (PACA) that can dynamically adjust its personality traits to better align with individual patient needs in therapeutic contexts. Based on established personality models and advances in NLP. | Proponemos el concepto de un agente conversacional adaptativo a la personalidad (PACA) que puede ajustar dinámicamente sus rasgos de personalidad para alinearse mejor con las necesidades individuales del paciente en contextos terapéuticos. | https://pmc.ncbi.nlm.nih.gov/articles/PMC8889396/ | Inglés | 2024 | Equipo de investigación en informática de salud mental | personality-adaptive conversational agents, mental health care, therapeutic chatbots, user personalization, patient-centered design, Big Five personality, clinical applications |
| 112 | Can ChatGPT Assess Human Personalities? A General Evaluation Framework | ¿Puede ChatGPT Evaluar Personalidades Humanas? Un Marco de Evaluación General | We present a generic evaluation framework for LLMs to assess human personalities based on MBTI tests. We devise unbiased prompts and propose three evaluation metrics to measure consistency, robustness, and fairness of assessment results from ChatGPT and GPT-4. | Presentamos un marco de evaluación genérico para que los LLMs evalúen personalidades humanas basado en pruebas MBTI. Diseñamos prompts imparciales y proponemos tres métricas de evaluación para medir la consistencia, robustez y equidad. | https://arxiv.org/abs/2303.01248 | Inglés | 2023 | Haocong Rao, Cyril Leung, Chunyan Miao | large language models, ChatGPT, personality assessment, MBTI, evaluation framework, prompt engineering, consistency |
| 113 | Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation | Evaluación Sistemática de GPT-3 para Estimación de Personalidad de Cero Disparos | We investigate zero-shot ability of GPT-3 to estimate Big 5 personality traits from social media posts. We find that zero-shot GPT-3 performance is somewhat close to existing pre-trained SotA for broad classification upon injecting knowledge about the trait in prompts. | Investigamos la capacidad de cero disparos de GPT-3 para estimar rasgos de personalidad de los Cinco Grandes desde publicaciones de redes sociales. Encontramos que el rendimiento de cero disparos de GPT-3 es algo cercano al SotA preentrenado existente. | https://aclanthology.org/2023.wassa-1.34.pdf | Inglés | 2023 | Adithya V Ganesan, Yash Kumar Lal, August Håkan Nilsson, H. Andrew Schwartz | personality estimation, GPT-3, zero-shot learning, Big Five traits, social media analysis, human-level NLP, psychometrics |
| 114 | The Plasticity of ChatGPT's Mentalizing Abilities: Personalization for Personality Structures | La Plasticidad de las Habilidades de Mentalización de ChatGPT: Personalización para Estructuras de Personalidad | We evaluated ChatGPT's potential to generate mentalizing-like abilities tailored to specific personality structure. ChatGPT accurately described emotional reactions of individuals with BPD as more intense, complex, and rich than those with SPD, suggesting it can generate mentalizing-like responses consistent with psychopathologies. | Evaluamos el potencial de ChatGPT para generar habilidades similares a la mentalización adaptadas a una estructura de personalidad específica. ChatGPT describió con precisión las reacciones emocionales de individuos con BPD como más intensas, complejas y ricas. | https://pmc.ncbi.nlm.nih.gov/articles/PMC10503434/ | Inglés | 2023 | Dorit Hadar-Shoval, Zohar Elyoseph, Maya Lvovsky | artificial intelligence, borderline personality disorder, emotional intelligence, empathy, emotional awareness, Schizoid Personality Disorder, mentalizing |
| 115 | Evaluating and Inducing Personality in Pre-trained Language Models | Evaluando e Induciendo Personalidad en Modelos de Lenguaje Preentrenados | We introduce the Machine Personality Inventory (MPI) tool for studying machine behaviors based on Big Five Personality Factors theory. By systematically evaluating LLMs with MPI, we provide first evidence demonstrating efficacy of MPI in studying LLM behaviors. We devise Personality Prompting (P^2) method to induce LLMs with specific personalities. | Introducimos la herramienta de Inventario de Personalidad de Máquina (MPI) para estudiar comportamientos de máquina basados en la teoría de los Factores de Personalidad de los Cinco Grandes. Al evaluar sistemáticamente LLMs con MPI, proporcionamos la primera evidencia que demuestra la eficacia de MPI. | https://arxiv.org/abs/2206.07550 | Inglés | 2022 | Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, Yixin Zhu | Machine Personality Inventory, Big Five personality traits, LLM evaluation, personality prompting, psychometric testing, pre-trained language models, behavioral assessment |
| 116 | Who is GPT-3? An Exploration of Personality, Values and Demographics | ¿Quién es GPT-3? Una Exploración de Personalidad, Valores y Demografía | We administered two validated measurement tools to GPT-3 to assess its personality, values it holds and self-reported demographics. Results show that GPT-3 scores similarly to human samples in terms of personality and values. We provide first evidence of psychological assessment of GPT-3 model. | Administramos dos herramientas de medición validadas a GPT-3 para evaluar su personalidad, los valores que sostiene y la demografía auto-reportada. Los resultados muestran que GPT-3 puntúa de manera similar a muestras humanas en términos de personalidad. | https://arxiv.org/abs/2209.14338 | Inglés | 2022 | Marilù Miotto, Nicola Rossberg, Bennett Kleinberg | GPT-3, personality assessment, psychological evaluation, human values, HEXACO personality model, computational social science, language model characterization |
| 117 | Identifying and Manipulating the Personality Traits of Language Models | Identificando y Manipulando los Rasgos de Personalidad de Modelos de Lenguaje | We explore whether perceived personality in language models is exhibited consistently in their language generation. We show that when provided different types of contexts, language models such as BERT and GPT2 can consistently identify and reflect personality markers. This frames them as tools for identifying personality traits and controlling personas. | Exploramos si la personalidad percibida en modelos de lenguaje se exhibe consistentemente en su generación de lenguaje. Mostramos que cuando se proporcionan diferentes tipos de contextos, modelos de lenguaje como BERT y GPT2 pueden identificar y reflejar marcadores de personalidad consistentemente. | https://arxiv.org/abs/2212.10276 | Inglés | 2022 | Graham Caron, Shashank Srivastava | personality traits, Big Five, language model control, persona manipulation, BERT, GPT-2, personality consistency |
| 118 | Estimating the Personality of White-Box Language Models | Estimando la Personalidad de Modelos de Lenguaje de Caja Blanca | We explore personality traits of several large-scale language models designed for open-ended text generation. We build on Big Five factors and develop robust methods that quantify personality traits of these models and their underlying datasets. We trigger models with personality assessment questionnaire and classify text responses into quantifiable traits. | Exploramos los rasgos de personalidad de varios modelos de lenguaje a gran escala diseñados para generación de texto abierto. Nos basamos en los factores de los Cinco Grandes y desarrollamos métodos robustos que cuantifican los rasgos de personalidad de estos modelos. | https://arxiv.org/abs/2204.12000 | Inglés | 2022 | Saketh Reddy Karra, Son The Nguyen, Theja Tulabandhula | white-box language models, Big Five personality, zero-shot classification, personality estimation, open-ended text generation, model anthropomorphism, personality modification |
| 119 | Pushing on Personality Detection from Verbal Behavior: A Transformer Meets Text Contours | Avanzando en la Detección de Personalidad desde el Comportamiento Verbal: Un Transformer Encuentra Contornos de Texto | We report two major improvements in predicting personality traits from text: (1) most comprehensive set of theory-based psycholinguistic features and (2) hybrid models integrating pre-trained Transformer BERT and BLSTM networks trained on within-text distributions of psycholinguistic features. Models achieve improvement by 2.9% on Essay dataset and 8.28% on Kaggle MBTI dataset. | Reportamos dos mejoras importantes en la predicción de rasgos de personalidad desde texto: (1) el conjunto más completo de características psicolingüísticas basadas en teoría y (2) modelos híbridos que integran el Transformer preentrenado BERT y redes BLSTM entrenadas en distribuciones intra-texto de características psicolingüísticas. | https://arxiv.org/abs/2204.04629 | Inglés | 2022 | Yu Qiao, Gian-Gabriel P. Garcia, Simon E. Coles, Daniel M. Olson, Apara Datta, Hareesh Kumar Krishnamohan, Vidhya Navalpakkam, Elisabeth André, Kai Zhao | personality detection, psycholinguistic features, BERT transformers, text contours, Big Five, MBTI, verbal behavior analysis |
